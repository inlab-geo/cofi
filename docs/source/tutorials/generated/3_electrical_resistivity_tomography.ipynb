{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 - Electrical resistivity tomography\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/tutorials/3_electrical_resistivity_tomography.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# What we do in this notebook\n\nHere we look at applying CoFI to an electrical resistivity tomography\nproblem, and explore different iterative non linear solvers.\n\n------------------------------------------------------------------------\n\n# Learning outcomes\n\n-   A demonstration of CoFI's ability to interface with PyGIMLi\n    (Geophysical Inversion and Modelling Library), a mature package to\n    solve the ERT forward problem\n-   An expos\u00e9 of CoFI's ability to interface with the iterative\n    non-linear solvers in SciPy specifically `scipy.optimize` and\n    PyTorch specificially `torch.optim`\n-   An illustration of how CoFI can be used to identify the most\n    appropriate iterative non-linear solver for a given problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Environment setup (uncomment code lines below)\n\n# !pip install -U cofi geo-espresso\n\n# !pip install -q condacolab\n# import condacolab\n# condacolab.install()\n# !mamba install -c gimli pygimli=1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you see a warning message from Colab - don't worry, this is expected.\nThis happens when we've successfully installed a package manager\n(\"mamba\") so that we can then install PyGIMLi (from conda channel\n\"gimli\").\n\n![image](https://i.imgur.com/TKAXUoA.png)\n\nRemember to uncomment and run the code cell below as well, as we are\ngoing to load some data from GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/inlab-geo/cofi-examples.git\n# %cd cofi-examples/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem description\n\nElectrical resistivity tomography is the inversion of measurements of\napparent electrical resistivities measured between electrodes placed at\nthe surface. A measured/known current is applied to one electrode pair\nand a second electrode pair is used to measure the voltage, this then\nallows to compute an apparent resistivity between the two electrode\npairs. Its applications include the detection and delineation of\ngroundwater resources, fracture zones, clay formations and the\nmonitoring of pollution plumes.\n\nHere we illustrate the expandability of CoFI by combining a mature\nPython library for geophysical inversion that implements one iterative\nnon-linear inversion method (Newton step with line search) for ERT\n(PyGIMLI <https://www.pygimli.org/>) with the iterative non linear\nsolvers we have made available in CoFI. In the following the forward\nproblem will be solved using PyGIMLI, while the inverse problem will be\nsolved using CoFI.\n\nThe objective function we are minimizing is given as:\n\n$$\\Psi(\\mathbf{m}) = (\\mathbf{d} -\\mathrm{f}(\\mathbf{m}))^{\\mathrm{T}} C_{d}^{-1}(\\mathbf{d} -\\mathrm{f}(\\mathbf{m}))^{\\mathrm{T}} + \\lambda \\mathbf{m}^{T} W^{\\mathrm{T}} W \\mathbf{{m}},$$\n\nwhere $\\mathbf{d}$ represents the data vector of measured apparent\nresistivties, $\\mathrm{f}(\\mathbf{m})$ is the model prediction,\n$C_d^{-1}$ is the inverse of the data covariance matrix, $W$ the model\nsmoothing matrix, $\\mathbf{m}$ the model vector and $\\lambda$ a\nregularization factor.\n\nThe model update is then given as\n\n$$\\begin{equation} \\Delta \\mathbf{m}= (\\underbrace{\\mathbf{J}^T \\mathbf{C}_d^{-1} \\mathbf{J}+\\lambda W^{T} W}_{\\mathbf{Hessian}})^{-1}\n(\\underbrace{ \\mathbf{J}^T\\mathbf{C}_d^{-1} \n(\\mathbf{d}-\\mathrm{f}(\\mathbf{m}))+\\lambda W^{T} W \\mathbf{m}}_{\\mathbf{Gradient}}),\n\\end{equation}$$\n\nwhere $J$ represents the Jacobian.\n\nSuccessful inversion also relies on the objective function being smooth\nand predictable. For apparent resistivity data it is advantageous to\nconvert measurements and model parameters to scale logarithmically to\nobtain a smoother and more predictable objective function when compared\nwith using the unscaled data and unscaled model parameters.\n\n## Further reading\n\n-   R\u00fccker, C., G\u00fcnther, T., & Spitzer, K. (2006). Three-dimensional\n    modelling and inversion of dc resistivity data incorporating\n    topography -- I. Modelling. Geophys. J. Int, 166, 495--505.\n    <https://doi.org/10.1111/j.1365-246X.2006.03010.x>\n-   G\u00fcnther, T., R\u00fccker, C., & Spitzer, K. (2006). Three-dimensional\n    modelling and inversion of dc resistivity data incorporating\n    topography - II. Inversion. Geophysical Journal International,\n    166(2), 506--517. <https://doi.org/10.1111/J.1365-246X.2006.03011.X>\n-   Wheelock, B., Constable, S., & Key, K. (2015). The advantages of\n    logarithmically scaled data for electromagnetic inversion.\n    Geophysical Journal International, 201(3), 1765--1780.\n    <https://doi.org/10.1093/GJI/GGV107>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interfacing to PyGIMLi\n\nPyGIMLi provides all the functionality to compute the apparent\nresistivities and Jacobian given a model. One of our goals around CoFI\nis to *never reinvent the wheel* and thus in the following we will -rely\non PyGIMLi's functionality to plot the model and data; and - use\nPyGIMLi's capabilities to compute the response and the Jacobian from a\nmodel.\n\nTo achieve this we first define a set of utility functions that will\nfacilitate interfacing to PyGIMLi. We will also show how CoFI can\ndirectly interface with a mature package without the need to go via\n[Espresso](https://geo-espresso.readthedocs.io/en/latest/).\n\nPyGIMLi uses different meshes and adaptive meshing capabilities via Gmsh\n<https://gmsh.info/>, all CoFI needs to access are the model vector, the\nJacobian, the regularization matrix and the model prediction. This makes\nfor a minimal interface.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pygimli\nfrom pygimli.physics import ert\nfrom pygimli import meshtools\n\nfrom cofi import BaseProblem, InversionOptions, Inversion\n\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title utility functions (hidden)\n############# Utility functions using PyGIMLi ##############################################\n\n# inversion mesh bound\nx_inv_start = -5\nx_inv_stop = 55\ny_inv_start = -20\ny_inv_stop = 0\nx_invmesh = np.linspace(start=x_inv_start, stop=x_inv_stop, num=40)\ny_invmesh = np.linspace(start=y_inv_start,stop=y_inv_stop,num=10)\n\n# Dipole Dipole (dd) measuring scheme\ndef survey_scheme(start=0, stop=50, num=51, schemeName=\"dd\"):\n    scheme = ert.createData(elecs=np.linspace(start=start, stop=stop, num=num),schemeName=schemeName)\n    return scheme\n\n# true geometry, forward mesh and true model\ndef model_true(scheme, start=[-55, 0], end=[105, -80], anomaly_pos=[10,-7], anomaly_rad=5):\n    world = meshtools.createWorld(start=start, end=end, worldMarker=True)\n    for s in scheme.sensors():          # local refinement \n        world.createNode(s + [0.0, -0.1])\n    conductive_anomaly = meshtools.createCircle(pos=anomaly_pos, radius=anomaly_rad, marker=2)\n    geom = world + conductive_anomaly\n    rhomap = [[1, 200], [2,  50],]\n    mesh = meshtools.createMesh(geom, quality=33)\n    return mesh, rhomap\n\n# PyGIMLi ert.ERTManager\ndef ert_manager(data, verbose=False):\n    return ert.ERTManager(data, verbose=verbose, useBert=True)\n\n# inversion mesh\ndef inversion_mesh(ert_mgr):\n    inv_mesh = ert_mgr.createMesh(ert_mgr.data)\n    # print(\"model size\", inv_mesh.cellCount())   # 1031\n    ert_mgr.setMesh(inv_mesh)\n    return inv_mesh\n\n# inversion mesh rectangular (the above is by default triangular)\ndef inversion_mesh_rect(ert_manager):\n    inv_mesh = pygimli.createGrid(x=x_invmesh, y=y_invmesh, marker=2)\n    inv_mesh = pygimli.meshtools.appendTriangleBoundary(inv_mesh, marker=1, xbound=50, ybound=50)\n    # print(\"model size\", inv_mesh.cellCount())    # 1213\n    ert_manager.setMesh(inv_mesh)\n    return inv_mesh\n\n# PyGIMLi ert.ERTModelling\ndef ert_forward_operator(ert_manager, scheme, inv_mesh):\n    forward_operator = ert_manager.fop\n    forward_operator.setComplex(False)\n    forward_operator.setData(scheme)\n    forward_operator.setMesh(inv_mesh, ignoreRegionManager=True)\n    return forward_operator\n\n# regularization matrix\ndef reg_matrix(forward_oprt):\n    region_manager = forward_oprt.regionManager()\n    region_manager.setConstraintType(2)\n    Wm = pygimli.matrix.SparseMapMatrix()\n    region_manager.fillConstraints(Wm)\n    Wm = pygimli.utils.sparseMatrix2coo(Wm)\n    return Wm\n\n# initialise model\ndef starting_model(ert_mgr, val=None):\n    data = ert_mgr.data\n    start_val = val if val else np.median(data['rhoa'].array())     # this is how pygimli initialises\n    start_model = np.ones(ert_mgr.paraDomain.cellCount()) * start_val\n    start_val_log = np.log(start_val)\n    start_model_log = np.ones(ert_mgr.paraDomain.cellCount()) * start_val_log\n    return start_model, start_model_log\n\n# convert model to numpy array\ndef model_vec(rhomap, fmesh):\n    model_true = pygimli.solver.parseArgToArray(rhomap, fmesh.cellCount(), fmesh)\n    return model_true\n\n# plot colorbar for model\ndef colorbar_model(ax, init=False, orientation=\"horizontal\"):\n    val_min = 170 if init else rhomap[1][1]\n    val_max = 230 if init else rhomap[0][1]\n    norm = mpl.colors.Normalize(val_min, val_max)\n    sm = plt.cm.ScalarMappable(norm=norm)\n    cb = plt.colorbar(sm, orientation=orientation, ax=ax)\n    cb.set_label(r'$\\Omega \\mathrm{m}$')\n    cb.set_ticks(np.arange(val_min, val_max+1, 30))\n\n# plot colorbar for data\ndef colorbar_data(ax, orientation=\"horizontal\"):\n    norm = mpl.colors.Normalize(min(data[\"rhoa\"]), max(data[\"rhoa\"]))\n    sm = plt.cm.ScalarMappable(norm=norm)\n    cb = plt.colorbar(sm, orientation=orientation, ax=ax)\n    cb.set_label(r'$\\Omega \\mathrm{m}$')\n    cb.set_ticks(np.arange(min(data[\"rhoa\"]), max(data[\"rhoa\"]), 30))\n    \n# plot true model, inferred model, provided data and synthetic data from inv_result\ndef plot_result(inv_result, title=None):\n    # convert back to normal space from log space\n    model = np.exp(inv_result.model)\n\n    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n    if title is not None:\n        fig.suptitle(title, fontsize=16)\n\n    # plot inferred model\n    # inv_result.summary()\n    pygimli.show(ert_mgr.paraDomain, data=model, label=r\"$\\Omega m$\", ax=axes[0], cMax=rhomap[0][1], cMin=rhomap[1][1], colorBar=False)\n    axes[0].set_title(\"Inferred model\")\n    axes[0].set_xlabel(\"Horizontal Distance (m)\")\n    axes[0].set_ylabel(\"Elevation (m)\")\n\n    # plot the true model\n    pygimli.show(mesh, data=rhomap, label=\"$\\Omega m$\", showMesh=True, ax=axes[1], colorBar=False)\n    axes[1].set_xlim(x_inv_start, x_inv_stop)\n    axes[1].set_ylim(y_inv_start, y_inv_stop)\n    axes[1].set_title(\"True model\")\n    axes[1].set_xlabel(\"Horizontal Distance (m)\")\n    colorbar_model(axes, orientation=\"vertical\")\n\n    # plot the data\n    _, axes = plt.subplots(1, 2, figsize=(12,4))\n\n    # plot synthetic data\n    d = forward_oprt.response(model)\n    ert.show(scheme, vals=d, cMin=np.min(data[\"rhoa\"]), cMax=np.max(data[\"rhoa\"]), ax=axes[0], colorBar=False)\n    axes[0].set_title(\"Synthetic data from inferred model\")\n    axes[0].set_xlabel(\"Horizontal Distance (m)\")\n    axes[0].set_ylabel(\"Dipole Dipole Separation (m)\")\n    # plot given data\n    ert.show(data, ax=axes[1], colorBar=False)\n    axes[1].set_title(\"Provided data\")\n    axes[1].set_xlabel(\"Horizontal Distance (m)\")\n    colorbar_data(axes, orientation=\"vertical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# True model\n\nOur example is centred around inverting dipole dipole measurements of\napparent resistivities in 2D with a circular shaped low resistivity\nanomaly.\n\n## Further reading\n\n<https://www.agiusa.com/dipole-dipole%E2%80%8B-%E2%80%8Barray%E2%80%8B>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# PyGIMLi - define measuring scheme, geometry, forward mesh and true model\nscheme = survey_scheme()\nmesh, rhomap = model_true(scheme)\n\n# plot the true model\n_, ax = plt.subplots(figsize=(10,8))\npygimli.show(mesh, data=rhomap, label=\"$\\Omega \\mathrm{m}$\", showMesh=True, ax=ax, colorBar=False)\nax.set_xlim(x_inv_start, x_inv_stop)\nax.set_ylim(y_inv_start, y_inv_stop)\nax.set_title(\"True model\")\nax.set_xlabel(\"Horizontal Distance (m)\")\nax.set_ylabel(\"Elevation (m)\")\ncolorbar_model(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ERT measurements consist of the apparent resistivity measured between\nmultiple electrode pairs and they are commonly plotted as\npseudosections. The model response for the true model has been\npreviously computed with PyGIMLi and noise has been added with the\nmagnitude of the noise depending on the dipole dipole separation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load data and covariance matrix\nlog_data = np.loadtxt(\"3_ert_data_log.txt\")\ndata_cov_inv = np.loadtxt(\"3_ert_data_cov_inv.txt\")\n\n# create PyGIMLi's ERT manager\nert_mgr = ert_manager(\"3_ert_data.dat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot data\ndata = ert_mgr.data\n_, ax = plt.subplots(figsize=(10,8))\nert.show(data, ax=ax, colorBar=False)\nax.set_title(\"Provided data\")\nax.set_xlabel(\"Horizontal Distance (m)\")\nax.set_ylabel(\"Dipole Dipole Separation (m)\")\ncolorbar_data(ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forward operator\n\nPyGIMLi solves the ERT forward problem accurately and efficiently by\ndefining boundary cells or ghost cells around the region of interest and\ncreating an optimal triangular mesh. This is all handled by PyGIMLi and\nGmsh and the model vector for the purpose of the inversion are the cells\nplotted in yellow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_mesh = inversion_mesh(ert_mgr)\n_, ax = plt.subplots(figsize=(10,8))\npygimli.show(inv_mesh, showMesh=True, markers=True, colorBar=False, ax=ax)\nax.set_title(\"Mesh used for inversion\");\nax.set_xlabel(\"Horizontal Distance (m)\");\nax.set_ylabel(\"Elevation (m)\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# PyGIMLi's forward operator (ERTModelling)\nforward_oprt = ert_forward_operator(ert_mgr, scheme, inv_mesh)\n\n# extract regularisation matrix\nWm = reg_matrix(forward_oprt)\n\n# initialise a starting model for inversion\nstart_model, start_model_log = starting_model(ert_mgr)\n_, ax = plt.subplots(figsize=(10,8))\npygimli.show(ert_mgr.paraDomain, data=start_model, label=\"$\\Omega m$\", showMesh=True, colorBar=False, cMin=170, cMax=230, ax=ax)\nax.set_title(\"Starting model\")\nax.set_xlabel(\"Horizontal Distance (m)\");\nax.set_ylabel(\"Elevation (m)\");\ncolorbar_model(ax, init=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step is to define the functions for CoFI. Typically, a given\ninversion solver will only require a subset of the functions we define\nin the following but in this example we would like to explore a wide\nrange of solvers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title additional utility functions (hidden)\n############# Functions provided to CoFI ##############################################\n\n## Note: all functions below assume the model in log space!\n\ndef _ensure_numpy(model):\n    if \"torch.Tensor\" in str(type(model)):\n        model = model.cpu().detach().numpy()\n    return model\n\ndef get_response(model, forward_operator):\n    model = _ensure_numpy(model)\n    return np.log(np.array(forward_operator.response(np.exp(model))))\n\ndef get_residual(model, log_data, forward_operator):\n    response = get_response(model, forward_operator)\n    residual = log_data - response\n    return residual\n\ndef get_jacobian(model, forward_operator):\n    response = get_response(model, forward_operator)\n    model = _ensure_numpy(model)\n    forward_operator.createJacobian(np.exp(model))\n    J = np.array(forward_operator.jacobian())\n    jac = J / np.exp(response[:, np.newaxis]) * np.exp(model)[np.newaxis, :]\n    return jac\n\ndef get_jac_residual(model, log_data, forward_operator):\n    response = get_response(model, forward_operator)\n    residual = log_data - response\n    model = _ensure_numpy(model)\n    forward_operator.createJacobian(np.exp(model))\n    J = np.array(forward_operator.jacobian())\n    jac = J / np.exp(response[:, np.newaxis]) * np.exp(model)[np.newaxis, :]\n    return jac, residual\n\ndef get_data_misfit(model, log_data, forward_operator, data_cov_inv=None):\n    residual = get_residual(model, log_data, forward_operator)\n    data_cov_inv = np.eye(log_data.shape[0]) if data_cov_inv is None else data_cov_inv\n    return np.abs(residual.T @ data_cov_inv @ residual)\n\ndef get_regularization(model, Wm, lamda):\n    model = _ensure_numpy(model)\n    model = np.exp(model)\n    return lamda * (Wm @ model).T @ (Wm @ model)\n\ndef get_objective(model, log_data, forward_operator, Wm, lamda, data_cov_inv=None):\n    data_misfit = get_data_misfit(model, log_data, forward_operator, data_cov_inv)\n    regularization = get_regularization(model, Wm, lamda)\n    obj = data_misfit + regularization\n    return obj\n\ndef get_gradient(model, log_data, forward_operator, Wm, lamda, data_cov_inv=None):\n    jac, residual = get_jac_residual(model, log_data, forward_operator)\n    data_cov_inv = np.eye(log_data.shape[0]) if data_cov_inv is None else data_cov_inv\n    data_misfit_grad =  - residual.T @ data_cov_inv @ jac\n    regularization_grad = lamda * Wm.T @ Wm @ np.exp(model)\n    return data_misfit_grad + regularization_grad\n\ndef get_hessian(model, log_data, forward_operator, Wm, lamda, data_cov_inv=None):\n    jac = get_jacobian(model, forward_operator)\n    data_cov_inv = np.eye(log_data.shape[0]) if data_cov_inv is None else data_cov_inv\n    hess = jac.T @ data_cov_inv @ jac + lamda * Wm.T @ Wm\n    return hess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoFI BaseProblem\n\nAs in the traveltime tomography example, we now use these functions to\ndefine our `BaseProblem`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# hyperparameters\nlamda = 0.0001\n\n# CoFI - define BaseProblem\nert_problem = BaseProblem()\nert_problem.name = \"Electrical Resistivity Tomography defined through PyGIMLi\"\nert_problem.set_forward(get_response, args=[forward_oprt])\nert_problem.set_jacobian(get_jacobian, args=[forward_oprt])\nert_problem.set_residual(get_residual, args=[log_data, forward_oprt])\nert_problem.set_data_misfit(get_data_misfit, args=[log_data, forward_oprt, data_cov_inv])\nert_problem.set_regularization(get_regularization, args=[Wm, lamda])\nert_problem.set_gradient(get_gradient, args=[log_data, forward_oprt, Wm, lamda, data_cov_inv])\nert_problem.set_hessian(get_hessian, args=[log_data, forward_oprt, Wm, lamda, data_cov_inv])\nert_problem.set_initial_model(start_model_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the `BaseProblem` defined, we can ask CoFI to list the solver\nlibraries we can use for our problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ert_problem.suggest_tools();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the traveltime tomography example we know that the\n`cofi.simple_newton` solver worked well so we will try it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Newton step\n\nThe Jacobian and Hessian are only local measures of the first and second\nderivatives of the objective function and given the ERT inverse problem\nis non-linear, we can no longer take the full Newton step to compute a\nmodel update. In practice:\n\n-   If the step length is chosen too large we may end up with a model\n    that is non-physical and the forward solver will crash and/or we\n    will overshoot.\n-   If the step size is chosen too small too many iterations might be\n    needed to reach convergence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_newton = InversionOptions()\ninv_options_newton.set_tool(\"cofi.simple_newton\")\ninv_options_newton.set_params(num_iterations=5, step_length=0.01)\n\ninv = Inversion(ert_problem, inv_options_newton)\ninv_result = inv.run()\n# inv_result.summary()\nprint(f\"\\nNumber of objective function evaluations: {inv_result.n_obj_evaluations}\")\nprint(f\"Number of gradient function evaluations: {inv_result.n_grad_evaluations}\")\nprint(f\"Number of hessian function evaluations: {inv_result.n_hess_evaluations}\")\n\nplot_result(inv_result, \"Newton Step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convergence of Newton's Method - A pathological example\n\nA simple illustrative example of the limitations around Newton's method\nis finding the $x$ where $f(x)=0$ for the following non-convex function:\n\n$f(x) = x^3 \u2212 2x + 2$, with $\\nabla f(x) = 3x^2 -2$ and \\$H_f(x) = 6 x\n\\$\n\nIf we start with $x=0$ or $x=1$ the result will oscillate between 0 and\n1 and never converge to the correct solution of $x\\approx -1.77$\n\n## Further reading\n\n<https://math.libretexts.org/Bookshelves/Calculus/Book%3A_Calculus_(OpenStax)/04%3A_Applications_of_Derivatives/4.09%3A_Newtons_Method>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scipy\nx0=0.1\nscipy.optimize.newton(lambda x: x**3-2*x+2, x0, fprime=lambda x: 3 * x**2-2,\n                       fprime2=lambda x: 6 * x,full_output=True, disp=True,maxiter=51)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyGIMLi uses a line search to determine the optimal step length, that\nmeans the descent direction is given by the full Newton Step with the\nlength adjusted so that it does not overshoot and results in an\nimprovement of the fit to the data. The major alternative to employing a\nline search is to employ a trust region method. Trust regions methods\ntry to estimate the region around the current model within which the\nassumption of local linearity holds and then limit the model update to\nstay within that region.\n\n# Further reading\n\n<https://medium.com/intro-to-artificial-intelligence/line-search-and-trust-region-optimisation-strategies-638a4a7490ca>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First challenge\n\nCoFI provides access to more sophisticated solvers that are available\nin - `scipy.optimize.minimize`\n<https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html>\n\nFor practical application we are interested in a solver that converges\nwith the fewest calls to the forward problem to a model that is\nacceptably close to the true model and explains the data. The\nconsequence of employing a line search or trust region method or more\nbroadly any method seeking to find the optimal step length is that\ntypically additional calls to a forward problem need to be made to\ndetermine the optimal step length and different approaches require\ndifferent numbers of calls to the forward problem depending on the shape\nof the objective function.\n\n*Which of the solvers from \\`\\`scipy.optimize.minimize\\`\\` result in an\nacceptable model with the fewest calls to the forward solver to compute\nthe model response and to the forward solver to compute the Jacobian? We\nsuggest to start with the following three solvers.* - \"newton-cg\"\n-<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-newtoncg.html> -\n\"dogleg\"\n-<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-dogleg.html> -\n\"trust-ncg\"-<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-trustncg.html>\n\n[![Upload to Jamboard\n1](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Jamboard-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://jamboard.google.com/d/1d-xjFfSi-TiQC64OOchgzmlhx5f4axtC7QZwGSbjyL4/edit?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title RUN ME - Utility Callback Function (hidden, no need to change)\n\nclass CallbackFunction:\n    def __init__(self):\n        self.x = None\n        self.i = 0\n\n    def __call__(self, xk):\n        print(f\"Iteration #{self.i+1}\")\n        if self.x is not None:\n            print(f\"  model change: {np.linalg.norm(xk - self.x)}\")\n        print(f\"  objective value: {ert_problem.objective(xk)}\")\n        self.x = xk\n        self.i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may start from the following template:\n\n    inv_options_scipy = InversionOptions()\n    inv_options_scipy.set_tool(\"scipy.optimize.minimize\")\n    inv_options_scipy.set_params(method=\"CHANGE ME\", options={\"maxiter\": 5}, callback=CallbackFunction())\n\n    inv = Inversion(ert_problem, inv_options_scipy)\n    inv_result = inv.run()\n    # inv_result.summary()\n    #print(f\"\\nSolver message: {inv_result.message}\")\n    print(f\"\\nNumber of objective function evaluations: {inv_result.nfev}\")\n    print(f\"Number of gradient function evaluations: {inv_result.njev}\")\n    print(f\"Number of hessian function evaluations: {inv_result.nhev}\")\n\n    plot_result(inv_result, \"CHANGE ME\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <CHANGE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution: scipy.optimize.minimize 'newton-cg' \n\ninv_options_scipy = InversionOptions()\ninv_options_scipy.set_tool(\"scipy.optimize.minimize\")\ninv_options_scipy.set_params(method=\"newton-cg\", options={\"maxiter\": 5}, callback=CallbackFunction())\n\ninv = Inversion(ert_problem, inv_options_scipy)\ninv_result = inv.run()\n# inv_result.summary()\n#print(f\"\\nSolver message: {inv_result.message}\")\nprint(f\"\\nNumber of objective function evaluations: {inv_result.nfev}\")\nprint(f\"Number of gradient function evaluations: {inv_result.njev}\")\nprint(f\"Number of hessian function evaluations: {inv_result.nhev}\")\n\nplot_result(inv_result, \"newton-cg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution: scipy.optimize.minimize 'dogleg' \n\ninv_options_scipy = InversionOptions()\ninv_options_scipy.set_tool(\"scipy.optimize.minimize\")\ninv_options_scipy.set_params(method=\"dogleg\", options={\"maxiter\": 5}, callback=CallbackFunction())\n    \ninv = Inversion(ert_problem, inv_options_scipy)\ninv_result = inv.run()\n# inv_result.summary()\nprint(f\"\\nNumber of objective function evaluations: {inv_result.nfev}\")\nprint(f\"Number of gradient function evaluations: {inv_result.njev}\")\nprint(f\"Number of hessian function evaluations: {inv_result.nhev}\")\n\nplot_result(inv_result, \"dogleg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution: scipy.optimize.minimize 'trust-krylov' \n\ninv_options_scipy = InversionOptions()\ninv_options_scipy.set_tool(\"scipy.optimize.minimize\")\ninv_options_scipy.set_params(method=\"trust-krylov\", options={\"maxiter\": 5}, callback=CallbackFunction())\n\ninv = Inversion(ert_problem, inv_options_scipy)\ninv_result = inv.run()\n# inv_result.summary()\nprint(f\"\\nNumber of objective function evaluations: {inv_result.nfev}\")\nprint(f\"Number of gradient function evaluations: {inv_result.njev}\")\nprint(f\"Number of hessian function evaluations: {inv_result.nhev}\")\n\nplot_result(inv_result, \"trust-krylov\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Second challenge\n\nIterative non linear optimisers can get trapped in a local minima,\nparticularly if there is noise present in the data or the forward\nproblem. The basic idea around momentum based solvers is that they\naccount for the history of the parameter updates similarly to a ball\nrolling down a hill gaining momentum. They do this by computing a\nweighted average over past gradients.\n<https://optimization.cbe.cornell.edu/index.php?title=Momentum>\n\nThe ADAM optimiser and it variants implement such a momentum approach\nand are frequently used in deep learning applications, for example to\ntrain a deep neural network.\n<https://optimization.cbe.cornell.edu/index.php?title=Adam>\n\nHere we will use the RAdam solver provided by pytorch and seek to find\nan optimal choice for the learning rate\n<https://pytorch.org/docs/stable/generated/torch.optim.RAdam.html>\n\n*Try to use \\`\\`RAdam\\`\\` from \\`\\`torch.optim\\`\\` and time permitting\nsee if you can find a better value for the learning rate \\`\\`lr=\\`\\`\nwhich plays a similar role as the step length.*\n\n[![Upload to Jamboard\n2](https://img.shields.io/badge/Click%20&%20upload%20your%20results%20to-Jamboard-lightgrey?logo=jamboard&style=for-the-badge&color=fcbf49&labelColor=edede9)](https://jamboard.google.com/d/13DkBtGDD2DQZWz9XqFgdx9PPpZJ91ZZcOOhTdITEvHY/edit?usp=sharing)\n\nYou may start from this template:\n\n    inv_options_torch = InversionOptions()\n    inv_options_torch.set_tool(\"CHANGE ME\")\n    inv_options_torch.set_params(algorithm=\"CHANGE ME\", lr=0.025, num_iterations=10, verbose=True)\n\n    inv = Inversion(ert_problem, inv_options_torch)\n    inv_result = inv.run()\n    # inv_result.summary()\n    print(f\"\\nNumber of objective function evaluations: {inv_result.n_obj_evaluations}\")\n    print(f\"Number of gradient function evaluations: {inv_result.n_grad_evaluations}\")\n\n    plot_result(inv_result, \"CHANGE ME\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Copy the template above, Replace <CHANGE ME> with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#@title Solution: torch.optim 'RAdam' \ninv_options_torch = InversionOptions()\ninv_options_torch.set_tool(\"torch.optim\")\ninv_options_torch.set_params(algorithm=\"RAdam\", lr=0.025, num_iterations=10, verbose=True)\n\ninv = Inversion(ert_problem, inv_options_torch)\ninv_result = inv.run()\n# inv_result.summary()\nprint(f\"\\nNumber of objective function evaluations: {inv_result.n_obj_evaluations}\")\nprint(f\"Number of gradient function evaluations: {inv_result.n_grad_evaluations}\")\n\nplot_result(inv_result, \"RAdam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A word about convergence criteria...\n\nWe have run each solver for a predetermined number of iterations and the\nrate at which the value of the objective function decreased was\ndifferent for the different solvers. Typically, iterative non-linear\nalgorithms terminate their iterations when a predefined fit to the data,\nminimum update to the model or minimum increase in fit to the data is\nachieved between subsequent iterations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Where to next?\n\n-   Induced polarisation example with a real dataset! - [link to\n    notebook](https://github.com/inlab-geo/cofi-examples/blob/main/examples/pygimli_dcip/pygimli_dcip_century_tri_mesh.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Watermark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"numpy\", \"scipy\", \"pygimli\", \"torch\", \"matplotlib\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}