{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1D Rayleigh wave phase velocity inversion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/tutorials/rayleigh_wave_phase_velocity/1D_rayleigh_wave_phase_velocity_inversion.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running this notebook locally, make sure you've followed\n[steps\nhere](https://github.com/inlab-geo/cofi-examples#run-the-examples-with-cofi-locally)\nto set up the environment. (This\n[environment.yml](https://github.com/inlab-geo/cofi-examples/blob/main/envs/environment.yml)\nfile specifies a list of packages required to run the notebooks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# What we do in this notebook\n\nHere we look at applying CoFI to the inversion of Rayleigh wave phase\nvelocities for a 1D layered earth.\n\n**Learning outcomes**\n\n-   A demonstration of CoFI's ability to switch between parameter\n    estimation and ensemble methods.\n-   A comparison between different McMC samplers that is fixed-d and\n    trans-d samplers\n-   An application of CoFI to field data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------- #\n#                                                          #\n#     Uncomment below to set up environment on \"colab\"     #\n#                                                          #\n# -------------------------------------------------------- #\n\n# !pip install -U cofi git+https://github.com/miili/pysurf96.git\n# !git clone https://github.com/inlab-geo/cofi-examples.git\n# %cd cofi-examples/examples/sw_rf_joint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\n\nfrom pysurf96 import surf96\nimport bayesbay\nimport cofi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem description\n\nHere we illustrate the range of inversion methods made avaialbe by CoFI.\nThat is we first define a base problem and then explore the use of an\niterative non linear apporach to find the MAP solution and then employ a\nrange of Markov Chain Monte Carlo strategies to recover the posterior\ndistribution. The forward problem is solved using pysurf 96\n(<https://github.com/miili/pysurf96>) and the field data example is\ntaken from\n(<https://www.eas.slu.edu/eqc/eqc_cps/TUTORIAL/STRUCT/index.html>) and\nwe will be inverting observed rayleigh wave phase velocities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Inference problem**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# display theory on the inference problem\nfrom IPython.display import display, Markdown\n\nwith open(\"../../theory/geo_surface_wave_dispersion.md\", \"r\") as f:\n    content = f.read()\n\ndisplay(Markdown(content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Solving methods**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# display theory on the optimisation approach\nwith open(\"../../theory/inv_optimisation.md\", \"r\") as f:\n    content = f.read()\n\ndisplay(Markdown(content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# display theory on the optimisation approach\nwith open(\"../../theory/inv_mcmc.md\", \"r\") as f:\n    content = f.read()\n\ndisplay(Markdown(content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Further reading**\n\n<https://en.wikipedia.org/wiki/Surface_wave_inversion>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1D model paramterisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# display theory on the 1D model parameterisation\nwith open(\"../../theory/misc_1d_model_parameterisation.md\", \"r\") as f:\n    content = f.read()\n\ndisplay(Markdown(content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# layercake model utilities\ndef form_layercake_model(thicknesses, vs):\n    model = np.zeros((len(vs)*2-1,))\n    model[1::2] = thicknesses\n    model[::2] = vs\n    return model\n\ndef split_layercake_model(model):\n    thicknesses = model[1::2]\n    vs = model[::2]\n    return thicknesses, vs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# voronoi model utilities\ndef form_voronoi_model(voronoi_sites, vs):\n    return np.hstack((vs, voronoi_sites))\n\ndef split_voronoi_model(model):\n    voronoi_sites = model[len(model)//2:]\n    vs = model[:len(model)//2]\n    return voronoi_sites, vs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def voronoi_to_layercake(voronoi_vector: np.ndarray) -> np.ndarray:\n    n_layers = len(voronoi_vector) // 2\n    velocities = voronoi_vector[:n_layers]\n    voronoi_sites = voronoi_vector[n_layers:]\n    depths = (voronoi_sites[:-1] + voronoi_sites[1:]) / 2\n    thicknesses = depths - np.insert(depths[:-1], 0, 0)\n    layercake_vector = np.zeros((2*n_layers-1,))\n    layercake_vector[::2] = velocities\n    layercake_vector[1::2] = thicknesses\n    return layercake_vector\n\ndef layercake_to_voronoi(layercake_vector: np.ndarray, first_voronoi_site: float = 0.0) -> np.ndarray:\n    n_layers = len(layercake_vector) // 2 + 1\n    thicknesses = layercake_vector[1::2]\n    velocities = layercake_vector[::2]\n    depths = np.cumsum(thicknesses)\n    voronoi_sites = np.zeros((n_layers,))\n    for i in range(1,len(voronoi_sites)):\n        voronoi_sites[i] = 2 * depths[i-1] - voronoi_sites[i-1]\n    voronoi_vector = np.hstack((velocities, voronoi_sites))\n    return voronoi_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forward solver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# display theory on the using the forward solver\nwith open(\"../../theory/geo_surface_wave_dispersion2.md\", \"r\") as f:\n    content = f.read()\n\ndisplay(Markdown(content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Constants\nVP_VS = 1.77\nRHO_VP_K = 0.32\nRHO_VP_B = 0.77"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# forward through pysurf96\ndef forward_sw(model, periods):\n    thicknesses, vs = split_layercake_model(model)\n    thicknesses = np.append(thicknesses, 10)\n    vp = vs * VP_VS\n    rho = RHO_VP_K * vp + RHO_VP_B\n    return surf96(\n        thicknesses,\n        vp,\n        vs,\n        rho,\n        periods,\n        wave=\"rayleigh\",\n        mode=1,\n        velocity=\"phase\",\n        flat_earth=False,\n    )\n\n# numerical jacobian\ndef jacobian_sw(model, periods, fwd=forward_sw, relative_step=0.01):\n    jacobian = np.zeros((len(periods), len(model)))\n    original_dpred = fwd(model, periods)\n    for i in range(len(model)):\n        perturbed_model = model.copy()\n        step = relative_step * model[i]\n        perturbed_model[i] += step\n        perturbed_dpred = fwd(perturbed_model, periods)\n        derivative = (perturbed_dpred - original_dpred) / abs(step)\n        jacobian[:, i] = derivative\n    return jacobian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisation\n\nFor conveninece we also implement two functions to plot the data here\nthe Rayleigh wave phase velocity and a model given in the layer based\nparametrisation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_model(model, ax=None, title=\"model\", **kwargs):\n    # process data\n    thicknesses = np.append(model[1::2], max(model[1::2]))\n    velocities = model[::2]\n    y = np.insert(np.cumsum(thicknesses), 0, 0)\n    x = np.insert(velocities, 0, velocities[0])\n    \n    # plot depth profile\n    if ax is None:\n        _, ax = plt.subplots()\n    plotting_style = {\n        \"linewidth\": kwargs.pop(\"linewidth\", kwargs.pop(\"lw\", 0.5)),\n        \"alpha\": 0.2,\n        \"color\": kwargs.pop(\"color\", kwargs.pop(\"c\", \"blue\")),\n    }\n    plotting_style.update(kwargs)\n    ax.step(x, y, where=\"post\", **plotting_style)\n    if ax.get_ylim()[0] < ax.get_ylim()[1]:\n        ax.invert_yaxis()\n    ax.set_xlabel(\"Vs (km/s)\")\n    ax.set_ylabel(\"Depth (km)\")\n    ax.set_title(title)\n    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_data(rayleigh_phase_velocities, periods, ax=None, scatter=False, \n              title=\"data\", **kwargs):\n    if ax is None:\n        _, ax = plt.subplots()\n    plotting_style = {\n        \"linewidth\": kwargs.pop(\"linewidth\", kwargs.pop(\"lw\", 1)),\n        \"alpha\": 1,\n        \"color\": kwargs.pop(\"color\", kwargs.pop(\"c\", \"blue\")),\n    }\n    plotting_style.update(**kwargs)\n    if scatter:\n        ax.scatter(periods, rayleigh_phase_velocities, **plotting_style)\n    else:\n        ax.plot(periods, rayleigh_phase_velocities, **plotting_style)\n    ax.set_xlabel(\"Periods (s)\")\n    ax.set_ylabel(\"Rayleigh phase velocities (km/s)\")\n    ax.set_title(title)\n    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_model_and_data(model, label_model, color_model, \n                        forward_func, periods, label_d_pred, color_d_pred, \n                        axes=None, light_thin=False):\n    if axes is None:\n        _, axes = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={\"width_ratios\": [1, 2.5]})\n    ax1, ax2 = axes\n    if light_thin:\n        plot_model(model, ax=ax1, color=color_model, alpha=0.2, lw=0.5, label=label_model)\n        plot_data(forward_func(model, periods), periods, ax=ax2, color=color_d_pred, alpha=0.2, lw=0.5, label=label_d_pred)\n    else:\n        plot_model(model, ax=ax1, color=color_model, alpha=1, lw=1, label=label_model)\n        plot_data(forward_func(model, periods), periods, ax=ax2, color=color_d_pred, label=label_d_pred)\n    ax1.legend()\n    ax2.legend()\n    return ax1, ax2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic example\n\nPrior to inverting any field data it is good practice to test an\ninversion method using sythetic exmaples where we know the true model.\nIt is also recommended to prior to this idnepently test any forward\nsolver that is being used and verify the Jacobian, as problems related\nto the forward sovler are diffiuclt to identify and diagnose once they\nare integrated in an inversion methodology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate synthetic data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "synth_d_periods = np.geomspace(3, 80, 20)\n\ntrue_thicknesses = np.array([10, 10, 15, 20, 20, 20, 20, 20])\ntrue_vs = np.array([3.38, 3.44, 3.66, 4.25, 4.35, 4.32, 4.315, 4.38, 4.5])\ntrue_model = form_layercake_model(true_thicknesses, true_vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise_level = 0.02\nd_true = forward_sw(true_model, synth_d_periods)\nd_obs = d_true + np.random.normal(0, 0.01, len(d_true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot true model and d_pred from true model\n_, ax2 = plot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"true data (noiseless)\", color_d_pred=\"orange\")\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=ax2, scatter=True, color=\"red\", s=20, label=\"observed data (noisy)\")\nax2.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Prepare \\`\\`BaseProblem\\`\\` for optimisation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_dims = 17\n\ninit_thicknesses = np.ones((n_dims//2,)) * 15\ninit_vs = np.ones((n_dims//2+1,)) * 4.0\ninit_model = form_layercake_model(init_thicknesses, init_vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"purple\",\n                           forward_func=forward_sw, periods=synth_d_periods, \n                           label_d_pred=\"data predictions from starting model\", color_d_pred=\"purple\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"true data (noiseless)\", color_d_pred=\"orange\", axes=axes)\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=axes[1], scatter=True, color=\"red\", s=20, label=\"d_obs\")\naxes[1].legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_reg = cofi.utils.QuadraticReg(\n    weighting_matrix=\"damping\", \n    model_shape=(n_dims,), \n    reference_model=init_model\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_objective(model, fwd, periods, d_obs, lamda=1.0):\n    d_pred = fwd(model, periods)\n    data_misfit = np.sum((d_obs - d_pred) ** 2)\n    reg = my_reg(model)\n    return data_misfit + lamda * reg\n\ndef my_objective_gradient(model, fwd, periods, d_obs, lamda=1.0):\n    d_pred = fwd(model, periods)\n    jac = jacobian_sw(model, periods, fwd)\n    data_misfit_grad = -2 * jac.T @ (d_obs - d_pred)\n    reg_grad = my_reg.gradient(model)\n    return data_misfit_grad + lamda * reg_grad\n\ndef my_objective_hessian(model, fwd, periods, d_obs, lamda=1.0):\n    jac = jacobian_sw(model, periods, fwd)\n    data_misfit_hess = 2 * jac.T @ jac\n    reg_hess = my_reg.hessian(model)\n    return data_misfit_hess + lamda * reg_hess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation with no damping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lamda = 0\n\nkwargs = {\n    \"fwd\": forward_sw, \n    \"periods\": synth_d_periods, \n    \"d_obs\": d_obs, \n    \"lamda\": lamda\n}\nsw_problem_no_reg = cofi.BaseProblem()\nsw_problem_no_reg.set_objective(my_objective, kwargs=kwargs)\nsw_problem_no_reg.set_gradient(my_objective_gradient, kwargs=kwargs)\nsw_problem_no_reg.set_hessian(my_objective_hessian, kwargs=kwargs)\nsw_problem_no_reg.set_initial_model(init_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`InversionOptions\\`\\`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_optimiser = cofi.InversionOptions()\ninv_options_optimiser.set_tool(\"scipy.optimize.minimize\")\ninv_options_optimiser.set_params(method=\"trust-exact\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_optimiser_no_reg = cofi.Inversion(sw_problem_no_reg, inv_options_optimiser)\ninv_result_optimiser_no_reg = inv_optimiser_no_reg.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw, periods=synth_d_periods, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"d_pred from true model\", color_d_pred=\"orange\", axes=axes)\n\n# plot the model and d_pred for inverted model\nplot_model_and_data(model=inv_result_optimiser_no_reg.model, label_model=\"inverted model\", color_model=\"purple\",\n                    forward_func=forward_sw, periods=synth_d_periods,\n                    label_d_pred=\"d_pred from inverted model\", color_d_pred=\"purple\", axes=axes);\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=axes[1], scatter=True, color=\"red\", s=20, label=\"d_obs\")\naxes[1].legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimal damping\n\nObviously we get a very skewed 1D model out of an optimisation that\nsolely tries to minimise the data misfit. We would like to add a damping\nterm to our objective function, but we are not sure which factor suits\nthe problem well.\n\nIn this situation, the `InversionPool` from CoFI can be handy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lambdas = np.logspace(-6, 6, 15)\n\nmy_lcurve_problems = []\nfor lamb in lambdas:\n    my_problem = cofi.BaseProblem()\n    kwargs = {\n        \"fwd\": forward_sw, \n        \"periods\": synth_d_periods, \n        \"d_obs\": d_obs, \n        \"lamda\": lamb\n    }\n    my_problem.set_objective(my_objective, kwargs=kwargs)\n    my_problem.set_gradient(my_objective_gradient, kwargs=kwargs)\n    my_problem.set_hessian(my_objective_hessian, kwargs=kwargs)\n    my_problem.set_initial_model(init_model)\n    my_lcurve_problems.append(my_problem)\n\ndef my_callback(inv_result, i):\n    m = inv_result.model\n    res_norm = np.linalg.norm(forward_sw(m, synth_d_periods) - d_obs)\n    reg_norm = np.sqrt(my_reg(m))\n    print(f\"Finished inversion with lambda={lambdas[i]}: {res_norm}, {reg_norm}\")\n    return res_norm, reg_norm\n\nmy_inversion_pool = cofi.utils.InversionPool(\n    list_of_inv_problems=my_lcurve_problems,\n    list_of_inv_options=inv_options_optimiser,\n    callback=my_callback,\n    parallel=False\n)\nall_res, all_cb_returns = my_inversion_pool.run()\n\nl_curve_points = list(zip(*all_cb_returns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# print all the lambdas\nlambdas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot L-curve**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the L-curve\nres_norm, reg_norm = l_curve_points\nplt.plot(reg_norm, res_norm, '.-')\nplt.xlabel(r'Norm of regularization term $||Wm||_2$')\nplt.ylabel(r'Norm of residual $||g(m)-d||_2$')\nfor i in range(0, len(lambdas), 2):\n    plt.annotate(f'{lambdas[i]:.1e}', (reg_norm[i], res_norm[i]), fontsize=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation with damping\n\nFrom the L-curve plot above, it seems that a damping factor of around\n0.02 would be good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lamda = 0.02\n\nkwargs = {\n    \"fwd\": forward_sw, \n    \"periods\": synth_d_periods, \n    \"d_obs\": d_obs, \n    \"lamda\": lamda\n}\nsw_problem = cofi.BaseProblem()\nsw_problem.set_objective(my_objective, kwargs=kwargs)\nsw_problem.set_gradient(my_objective_gradient, kwargs=kwargs)\nsw_problem.set_hessian(my_objective_hessian, kwargs=kwargs)\nsw_problem.set_initial_model(init_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_optimiser = cofi.Inversion(sw_problem, inv_options_optimiser)\ninv_result_optimiser = inv_optimiser.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw, periods=synth_d_periods, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"d_pred from true model\", color_d_pred=\"orange\", axes=axes)\n\n# plot the model and d_pred for damped solution, and d_obs\nplot_model_and_data(model=inv_result_optimiser.model, label_model=\"damped solution\", color_model=\"purple\",\n                    forward_func=forward_sw, periods=synth_d_periods,\n                    label_d_pred=\"d_pred from damped solution\", color_d_pred=\"purple\", axes=axes);\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=axes[1], scatter=True, color=\"red\", s=20, label=\"d_obs\")\naxes[1].legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fixed-dimensional sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Prepare \\`\\`BaseProblem\\`\\` for fixed-dimensional sampling**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thick_min = 5\nthick_max = 30\nvs_min = 2\nvs_max = 5\n\ndef my_log_prior(model):\n    thicknesses, vs = split_layercake_model(model)\n    thicknesses_out_of_bounds = (thicknesses < thick_min) | (thicknesses > thick_max)\n    vs_out_of_bounds = (vs < vs_min) | (vs > vs_max)\n    if np.any(thicknesses_out_of_bounds) or np.any(vs_out_of_bounds):\n        return float(\"-inf\")\n    log_prior = -np.log(thick_max - thick_min) * len(thicknesses) - np.log(vs_max - vs_min) * len(vs)\n    return log_prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Cdinv = np.eye(len(d_obs))/(noise_level**2)      # inverse data covariance matrix\n\ndef my_log_likelihood(model):\n    try:\n        d_pred = forward_sw(model, synth_d_periods)\n    except:\n        return float(\"-inf\")\n    residual = d_obs - d_pred\n    return -0.5 * residual @ (Cdinv @ residual).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_walkers = 40\n\nmy_walkers_start = np.ones((n_walkers, n_dims)) * inv_result_optimiser.model\nfor i in range(n_walkers):\n    my_walkers_start[i,:] += np.random.normal(0, 0.3, n_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sw_problem.set_log_prior(my_log_prior)\nsw_problem.set_log_likelihood(my_log_likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`InversionOptions\\`\\`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_fixed_d_sampling = cofi.InversionOptions()\ninv_options_fixed_d_sampling.set_tool(\"emcee\")\ninv_options_fixed_d_sampling.set_params(\n    nwalkers=n_walkers, \n    nsteps=2_000, \n    initial_state=my_walkers_start, \n    skip_initial_state_check=True, \n    progress=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will disable the display of warnings temporarily due to the\nunavoidable existence of `-inf` in our prior.\n\n<https://github.com/dfm/emcee/issues/370#issuecomment-1013623444>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.seterr(all=\"ignore\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sample the prior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior_sampling_problem = cofi.BaseProblem()\nprior_sampling_problem.set_log_posterior(my_log_prior)\nprior_sampling_problem.set_model_shape(init_model.shape)\nprior_sampler = cofi.Inversion(prior_sampling_problem, inv_options_fixed_d_sampling)\nprior_results = prior_sampler.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import arviz as az\n\nlabels = [\"v0\", \"t0\", \"v1\", \"t1\", \"v2\", \"t2\", \"v3\", \"t3\", \"v4\", \"t4\", \"v5\", \"t5\", \"v6\", \"t6\", \"v7\", \"t7\", \"v8\"]\n\nprior_results_sampler = prior_results.sampler\naz_idata_prior = az.from_emcee(prior_results_sampler, var_names=labels)\n\naxes = az.plot_trace(\n    az_idata_prior, \n    backend_kwargs={\"constrained_layout\":True}, \n    figsize=(10,20),\n)\n\nfor i, axes_pair in enumerate(axes):\n    ax1 = axes_pair[0]\n    ax2 = axes_pair[1]\n    ax1.set_xlabel(\"parameter value\")\n    ax1.set_ylabel(\"density value\")\n    ax2.set_xlabel(\"number of iterations\")\n    ax2.set_ylabel(\"parameter value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sample the posterior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inversion_fixed_d_sampler = cofi.Inversion(sw_problem, inv_options_fixed_d_sampling)\ninv_result_fixed_d_sampler = inversion_fixed_d_sampler.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = inv_result_fixed_d_sampler.sampler\naz_idata = az.from_emcee(sampler, var_names=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_idata.get(\"posterior\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"initial model for damped solution\", color_model=\"black\",\n                           forward_func=forward_sw, periods=synth_d_periods, \n                           label_d_pred=\"d_pred from initial model for damped solution\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"d_pred from true model\", color_d_pred=\"orange\", axes=axes)\n\n# plot the model and d_pred for damped solution, and d_obs\nplot_model_and_data(model=inv_result_optimiser.model, label_model=\"damped solution\", color_model=\"green\",\n                    forward_func=forward_sw, periods=synth_d_periods,\n                    label_d_pred=\"d_pred from damped solution\", color_d_pred=\"green\", axes=axes);\n\n# plot randomly selected samples and data predictions from samples\nflat_samples = sampler.get_chain(discard=500, thin=500, flat=True)\nrand_indices = np.random.randint(len(flat_samples), size=100)\nfor idx in rand_indices:\n    sample = flat_samples[idx]\n    label_model = \"sample models\" if idx == 0 else None\n    label_d_pred = \"d_pred from samples\" if idx == 0 else None\n    plot_model_and_data(model=sample, label_model=label_model, color_model=\"gray\",\n                        forward_func=forward_sw, periods=synth_d_periods,\n                        label_d_pred=label_d_pred, color_d_pred=\"gray\", axes=axes, light_thin=True)\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=axes[1], scatter=True, color=\"red\", s=20, label=\"d_obs\")\n\naxes[0].set_ylim(170)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "axes = az.plot_trace(\n    az_idata, \n    backend_kwargs={\"constrained_layout\":True},\n    figsize=(10,20)\n)\n\nfor i, axes_pair in enumerate(axes):\n    ax1 = axes_pair[0]\n    ax2 = axes_pair[1]\n    ax1.axvline(true_model[i], linestyle='dotted', color='red')\n    ax1.set_xlabel(\"parameter value\")\n    ax1.set_ylabel(\"density value\")\n    ax2.set_xlabel(\"number of iterations\")\n    ax2.set_ylabel(\"parameter value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**More steps?**\n\nDue to time restrictions, we have only run 2_000 steps above, which\nmight be enough for illustration purpose and sanity check, but are not\nenough for an actual inversion.\n\nOn a seperate experiment, we ran 200_000 steps instead and produced the\nfollowing samples plot.\n\n<figure>\n<img src=\"illustrations/emcee_200_000_iterations.png\"\nalt=\"illustrations/emcee_200_000_iterations.png\" />\n<figcaption>Fixed-dimensional sampling results with 200_000\nsteps</figcaption>\n</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trans-dimensional sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Prepare utilities for trans-dimensional sampling**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward_for_bayesbay(state):\n    vs = state[\"voronoi\"][\"vs\"]\n    voronoi_sites = state[\"voronoi\"][\"discretization\"]\n    depths = (voronoi_sites[:-1] + voronoi_sites[1:]) / 2\n    thicknesses = depths - np.insert(depths[:-1], 0, 0)\n    model = form_layercake_model(thicknesses, vs)\n    return forward_sw(model, synth_d_periods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "targets = [bayesbay.Target(\"rayleigh\", d_obs, covariance_mat_inv=1/noise_level**2)]\nfwd_funcs = [forward_for_bayesbay]\nmy_log_likelihood = bayesbay.LogLikelihood(targets, fwd_funcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_vs = bayesbay.prior.UniformPrior(\n    name=\"vs\", \n    vmin=[2.7, 3.2, 3.75], \n    vmax=[4, 4.75, 5], \n    position=[0, 40, 80], \n    perturb_std=0.15\n)\n\ndef param_vs_initialize(param, positions): \n    vmin, vmax = param.get_vmin_vmax(positions)\n    sorted_vals = np.sort(np.random.uniform(vmin, vmax, positions.size))\n    for i in range (len(sorted_vals)):\n        val = sorted_vals[i]\n        vmin_i = vmin if np.isscalar(vmin) else vmin[i]\n        vmax_i = vmax if np.isscalar(vmax) else vmax[i]\n        if val < vmin_i or val > vmax_i:\n            if val > vmax_i: sorted_vals[i] = vmax_i\n            if val < vmin_i: sorted_vals[i] = vmin_i\n    return sorted_vals\n\nparam_vs.set_custom_initialize(param_vs_initialize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameterization = bayesbay.parameterization.Parameterization(\n    bayesbay.discretization.Voronoi1D(\n        name=\"voronoi\", \n        vmin=0, \n        vmax=150, \n        perturb_std=10, \n        n_dimensions=None, \n        n_dimensions_min=4, \n        n_dimensions_max=15, \n        parameters=[param_vs], \n    )\n)\nmy_perturbation_funcs = parameterization.perturbation_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_chains=12\nwalkers_start = []\nfor i in range(n_chains):\n    walkers_start.append(parameterization.initialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`InversionOptions\\`\\`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_trans_d_sampling = cofi.InversionOptions()\ninv_options_trans_d_sampling.set_tool(\"bayesbay\")\ninv_options_trans_d_sampling.set_params(\n    walkers_starting_states=walkers_start,\n    perturbation_funcs=my_perturbation_funcs,\n    log_like_ratio_func=my_log_likelihood,\n    n_chains=n_chains, \n    n_iterations=3_000, \n    burnin_iterations=1_000,\n    verbose=False, \n    save_every=200, \n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inversion_trans_d_sampler = cofi.Inversion(sw_problem, inv_options_trans_d_sampling)\ninv_result_trans_d_sampler = inversion_trans_d_sampler.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverted_models = inv_result_trans_d_sampler.models\nsamples = []\nfor v, vs in zip(inverted_models[\"voronoi.discretization\"], inverted_models[\"voronoi.vs\"]):\n    sample = form_voronoi_model(v, vs)\n    samples.append(voronoi_to_layercake(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"initial model for damped solution\", color_model=\"black\",\n                           forward_func=forward_sw, periods=synth_d_periods, \n                           label_d_pred=\"d_pred from initial model for damped solution\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=true_model, label_model=\"true model\", color_model=\"orange\",\n                    forward_func=forward_sw, periods=synth_d_periods, \n                    label_d_pred=\"d_pred from true model\", color_d_pred=\"orange\", axes=axes)\n\n# plot the model and d_pred for damped solution, and d_obs\nplot_model_and_data(model=inv_result_optimiser.model, label_model=\"damped solution\", color_model=\"green\",\n                    forward_func=forward_sw, periods=synth_d_periods,\n                    label_d_pred=\"d_pred from damped solution\", color_d_pred=\"green\", axes=axes);\n\n# plot randomly selected samples and data predictions from samples\nfor i, sample in enumerate(samples):\n    label_model = \"sample models\" if i == 0 else None\n    label_d_pred = \"d_pred from samples\" if i == 0 else None\n    plot_model_and_data(model=sample, label_model=label_model, color_model=\"gray\",\n                        forward_func=forward_sw, periods=synth_d_periods,\n                        label_d_pred=label_d_pred, color_d_pred=\"gray\", axes=axes, light_thin=True)\n\n# plot d_obs\nplot_data(d_obs, synth_d_periods, ax=axes[1], scatter=True, color=\"red\", s=20, label=\"d_obs\")\n\naxes[0].set_ylim(170)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Field data example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Rayleigh observations**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "file_surf_data = \"../../data/sw_rf_joint/data/SURF/nnall.dsp\"\n\nwith open(file_surf_data, \"r\") as file:\n    lines = file.readlines()\n    surf_data = []\n    for line in lines:\n        row = line.strip().split()\n        if \"C\" in row:\n            surf_data.append([float(e) for e in row[5:8]])\n\nfield_d = np.array(surf_data)\nfield_d_periods = field_d[:,0]\nfield_d_obs = field_d[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plot_data(field_d_obs, field_d_periods, color=\"brown\", s=5, scatter=True,\n             label=\"d_obs\")\nax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reference good model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "file_end_mod = \"../../data/sw_rf_joint/data/SURF/end.mod\"\n\nwith open(file_end_mod, \"r\") as file:\n    lines = file.readlines()\n    ref_good_model = []\n    for line in lines[12:]:\n        row = line.strip().split()\n        ref_good_model.append([float(row[0]), float(row[2])])\n\nref_good_model = np.array(ref_good_model)\nref_good_model = form_layercake_model(ref_good_model[:-1,0], ref_good_model[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(figsize=(4,6))\nplot_model(ref_good_model, ax=ax, alpha=1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modified forward utility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward_sw_interp(model, periods=field_d_periods):\n    pysurf_periods = np.logspace(\n        np.log(np.min(periods)), \n        np.log(np.max(periods+1)), \n        60,\n        base=np.e, \n    )\n    pysurf_dpred = forward_sw(model, pysurf_periods)\n    interp_func = scipy.interpolate.interp1d(pysurf_periods, \n                                             pysurf_dpred, \n                                             fill_value=\"extrapolate\")\n    dpred = interp_func(periods)\n    return dpred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_dims = 29\n\ninit_thicknesses = np.ones((n_dims//2,)) * 10\ninit_vs = np.ones((n_dims//2+1,)) * 4.0\ninit_model = form_layercake_model(init_thicknesses, init_vs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_reg = cofi.utils.QuadraticReg(\n    weighting_matrix=\"damping\", \n    model_shape=(n_dims,), \n    reference_model=init_model\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation with no damping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lamda = 0\n\nkwargs = {\n    \"fwd\": forward_sw_interp,\n    \"periods\": field_d_periods, \n    \"d_obs\": field_d_obs, \n    \"lamda\": lamda, \n}\nsw_field_problem_no_reg = cofi.BaseProblem()\nsw_field_problem_no_reg.set_objective(my_objective, kwargs=kwargs)\nsw_field_problem_no_reg.set_gradient(my_objective_gradient, kwargs=kwargs)\nsw_field_problem_no_reg.set_hessian(my_objective_hessian, kwargs=kwargs)\nsw_field_problem_no_reg.set_initial_model(init_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_sw_field_problem_no_reg = cofi.Inversion(sw_field_problem_no_reg, inv_options_optimiser)\ninv_result_sw_field_no_reg = inv_sw_field_problem_no_reg.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "field_d_periods_logspace = np.logspace(\n    np.log(np.min(field_d_periods)), \n    np.log(np.max(field_d_periods+1)), \n    60, \n    base=np.e, \n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=ref_good_model, label_model=\"reference good model\", color_model=\"red\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                    label_d_pred=\"d_pred from reference good model\", color_d_pred=\"red\", axes=axes)\n\n# plot the model and d_pred for inverted model, and d_obs\nplot_model_and_data(model=inv_result_sw_field_no_reg.model, \n                    label_model=\"inverted model from field data\", color_model=\"purple\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                    label_d_pred=\"d_pred from inverted model\", color_d_pred=\"purple\", axes=axes)\n\n# plot d_obs\nplot_data(field_d_obs, field_d_periods, ax=axes[1], scatter=True, color=\"orange\", s=8, label=\"d_obs\")\n\naxes[0].set_ylim(100, 0)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimal damping\n\nAgain, we would like to find a good regularisation factor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lambdas = np.logspace(-6, 6, 15)\n\nmy_lcurve_problems = []\nfor lamb in lambdas:\n    my_problem = cofi.BaseProblem()\n    kwargs = {\n        \"fwd\": forward_sw_interp,\n        \"periods\": field_d_periods, \n        \"d_obs\": field_d_obs, \n        \"lamda\": lamb, \n    }\n    my_problem.set_objective(my_objective, kwargs=kwargs)\n    my_problem.set_gradient(my_objective_gradient, kwargs=kwargs)\n    my_problem.set_hessian(my_objective_hessian, kwargs=kwargs)\n    my_problem.set_initial_model(init_model)\n    my_lcurve_problems.append(my_problem)\n\ndef my_callback(inv_result, i):\n    m = inv_result.model\n    res_norm = np.linalg.norm(forward_sw_interp(m, field_d_periods) - field_d_obs)\n    reg_norm = np.sqrt(my_reg(m))\n    print(f\"Finished inversion with lambda={lambdas[i]}: {res_norm}, {reg_norm}\")\n    return res_norm, reg_norm\n\nmy_inversion_pool = cofi.utils.InversionPool(\n    list_of_inv_problems=my_lcurve_problems,\n    list_of_inv_options=inv_options_optimiser,\n    callback=my_callback,\n    parallel=False\n)\nall_res, all_cb_returns = my_inversion_pool.run()\n\nl_curve_points = list(zip(*all_cb_returns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# print all the lambdas\nlambdas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the L-curve\nres_norm, reg_norm = l_curve_points\nplt.plot(reg_norm, res_norm, '.-')\nplt.xlabel(r'Norm of regularization term $||Wm||_2$')\nplt.ylabel(r'Norm of residual $||g(m)-d||_2$')\nfor i in range(0, len(lambdas), 2):\n    plt.annotate(f'{lambdas[i]:.1e}', (reg_norm[i], res_norm[i]), fontsize=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimisation with damping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lamda = 0.14\n\nkwargs = {\n    \"fwd\": forward_sw_interp,\n    \"periods\": field_d_periods, \n    \"d_obs\": field_d_obs, \n    \"lamda\": lamda, \n}\nsw_field_problem = cofi.BaseProblem()\nsw_field_problem.set_objective(my_objective, kwargs=kwargs)\nsw_field_problem.set_gradient(my_objective_gradient, kwargs=kwargs)\nsw_field_problem.set_hessian(my_objective_hessian, kwargs=kwargs)\nsw_field_problem.set_initial_model(init_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_sw_field_problem = cofi.Inversion(sw_field_problem, inv_options_optimiser)\ninv_result_sw_field = inv_sw_field_problem.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=ref_good_model, label_model=\"reference good model\", color_model=\"red\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                    label_d_pred=\"d_pred from reference good model\", color_d_pred=\"red\", axes=axes)\n\n# plot the model and d_pred for inverted model, and d_obs\nplot_model_and_data(model=inv_result_sw_field.model, \n                    label_model=\"inverted model from field data\", color_model=\"purple\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                    label_d_pred=\"d_pred from inverted model\", color_d_pred=\"purple\", axes=axes)\n\n# plot d_obs\nplot_data(field_d_obs, field_d_periods, ax=axes[1], scatter=True, color=\"orange\", s=8, label=\"d_obs\")\n\naxes[0].set_ylim(100, 0)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fixed-dimensional sampling\n\nWe are going to use the same sets of log prior, and we will rewrite the\nlog likelihood function to apply on the field data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thick_min = 3\nthick_max = 10\nvs_min = 2\nvs_max = 5.5\n\ndef my_log_prior(model):\n    thicknesses, vs = split_layercake_model(model)\n    thicknesses_out_of_bounds = (thicknesses < thick_min) | (thicknesses > thick_max)\n    vs_out_of_bounds = (vs < vs_min) | (vs > vs_max)\n    if np.any(thicknesses_out_of_bounds) or np.any(vs_out_of_bounds):\n        return float(\"-inf\")\n    log_prior = - np.log(thick_max - thick_min) * len(thicknesses) \\\n                - np.log(vs_max - vs_min) * len(vs)\n    return log_prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# estimate the data noise\nd_pred_from_optimiser = forward_sw_interp(inv_result_sw_field.model, field_d_periods)\nnoise_level = np.std(field_d_obs - d_pred_from_optimiser)\nCdinv = np.eye(len(field_d_obs))/(noise_level**2)\n\nprint(f\"Estimated noise level: {noise_level}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def my_log_likelihood(model):\n    try:\n        d_pred = forward_sw_interp(model, field_d_periods)\n    except:\n        return float(\"-inf\")\n    residual = field_d_obs - d_pred\n    return -0.5 * residual @ (Cdinv @ residual).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_walkers = 60\n\nmy_walkers_start = np.ones((n_walkers, n_dims)) * inv_result_sw_field.model\nfor i in range(n_walkers):\n    my_walkers_start[i,:] += np.random.normal(0, 0.3, n_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sw_field_problem.set_log_prior(my_log_prior)\nsw_field_problem.set_log_likelihood(my_log_likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`InversionOptions\\`\\`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_fixed_d_sampling = cofi.InversionOptions()\ninv_options_fixed_d_sampling.set_tool(\"emcee\")\ninv_options_fixed_d_sampling.set_params(\n    nwalkers=n_walkers,\n    nsteps=20_000,\n    initial_state=my_walkers_start,\n    skip_initial_state_check=True,\n    progress=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sample the posterior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inversion_fixed_d_sampler_field = cofi.Inversion(sw_field_problem,\n                                                 inv_options_fixed_d_sampling)\ninv_result_fixed_d_sampler_field = inversion_fixed_d_sampler_field.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = inv_result_fixed_d_sampler.sampler\naz_idata = az.from_emcee(sampler, var_names=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_idata.get(\"posterior\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=ref_good_model, label_model=\"reference good model\", color_model=\"red\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                    label_d_pred=\"d_pred from reference good model\", color_d_pred=\"red\", axes=axes)\n\n# plot the model and d_pred for inverted model, and d_obs\nplot_model_and_data(model=inv_result_sw_field.model, \n                    label_model=\"inverted model from field data\", color_model=\"green\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                    label_d_pred=\"d_pred from inverted model\", color_d_pred=\"green\", axes=axes)\n\n# plot randomly selected samples and data predictions from samples\nflat_samples = sampler.get_chain(discard=1000, thin=300, flat=True)\nrand_indices = np.random.randint(len(flat_samples), size=100)\nfor idx in rand_indices:\n    sample = flat_samples[idx]\n    label_model = \"sample models\" if idx == 0 else None\n    label_d_pred = \"d_pred from samples\" if idx == 0 else None\n    plot_model_and_data(model=sample, label_model=label_model, color_model=\"gray\",\n                        forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                        label_d_pred=label_d_pred, color_d_pred=\"gray\", axes=axes, light_thin=True)\n\n# plot d_obs\nplot_data(field_d_obs, field_d_periods, ax=axes[1], scatter=True, color=\"orange\", s=8, label=\"d_obs\")\n\naxes[0].set_ylim(100, 0)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**More steps**\n\nSimilar to our earlier fixed-dimensional sampling run on the synthetic\ndata, we are not sampling enough due to time limit.\n\nOn a seperate experiment, we ran 200_000 steps and produced the\nfollowing samples plot.\n\n![](illustrations/emcee_200_000_iterations_field.png)\n\n> steps\n>\n> Fixed-dimensional sampling results on field data with 200_000 steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trans-dimensional sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward_interp_for_bayesbay(state):\n    vs = state[\"voronoi\"][\"vs\"]\n    voronoi_sites = state[\"voronoi\"][\"discretization\"]\n    depths = (voronoi_sites[:-1] + voronoi_sites[1:]) / 2\n    thicknesses = depths - np.insert(depths[:-1], 0, 0)\n    model = form_layercake_model(thicknesses, vs)\n    return forward_sw_interp(model, field_d_periods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "targets = [bayesbay.Target(\"rayleigh\", field_d_obs, covariance_mat_inv=1/noise_level**2)]\nfwd_funcs = [forward_interp_for_bayesbay]\nmy_log_likelihood = bayesbay.LogLikelihood(targets, fwd_funcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_vs = bayesbay.prior.UniformPrior(\n    name=\"vs\", \n    vmin=[2.7, 3.2, 3.75], \n    vmax=[4, 4.75, 5], \n    position=[0, 40, 80], \n    perturb_std=0.15\n)\n\ndef param_vs_initialize(param, positions): \n    vmin, vmax = param.get_vmin_vmax(positions)\n    sorted_vals = np.sort(np.random.uniform(vmin, vmax, positions.size))\n    for i in range (len(sorted_vals)):\n        val = sorted_vals[i]\n        vmin_i = vmin if np.isscalar(vmin) else vmin[i]\n        vmax_i = vmax if np.isscalar(vmax) else vmax[i]\n        if val < vmin_i or val > vmax_i:\n            if val > vmax_i: sorted_vals[i] = vmax_i\n            if val < vmin_i: sorted_vals[i] = vmin_i\n    return sorted_vals\n\nparam_vs.set_custom_initialize(param_vs_initialize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameterization = bayesbay.parameterization.Parameterization(\n    bayesbay.discretization.Voronoi1D(\n        name=\"voronoi\", \n        vmin=0, \n        vmax=150, \n        perturb_std=10, \n        n_dimensions=None, \n        n_dimensions_min=4, \n        n_dimensions_max=20, \n        parameters=[param_vs], \n    )\n)\nmy_perturbation_funcs = parameterization.perturbation_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_chains=12\nwalkers_start = []\nfor i in range(n_chains):\n    walkers_start.append(parameterization.initialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`InversionOptions\\`\\`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_field_trans_d_sampling = cofi.InversionOptions()\ninv_options_field_trans_d_sampling.set_tool(\"bayesbay\")\ninv_options_field_trans_d_sampling.set_params(\n    walkers_starting_states=walkers_start,\n    perturbation_funcs=my_perturbation_funcs,\n    log_like_ratio_func=my_log_likelihood,\n    n_chains=n_chains, \n    n_iterations=3_000, \n    burnin_iterations=1_000,\n    verbose=False, \n    save_every=200, \n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define \\`\\`Inversion\\`\\` and run**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inversion_field_trans_d_sampler = cofi.Inversion(sw_field_problem, \n                                                 inv_options_field_trans_d_sampling)\ninv_result_field_trans_d_sampler = inversion_field_trans_d_sampler.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverted_models = inv_result_field_trans_d_sampler.models\nsamples = []\nfor v, vs in zip(inverted_models[\"voronoi.discretization\"], inverted_models[\"voronoi.vs\"]):\n    sample = form_voronoi_model(v, vs)\n    samples.append(voronoi_to_layercake(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot the model and d_pred for starting model\naxes = plot_model_and_data(model=init_model, label_model=\"starting model\", color_model=\"black\",\n                           forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                           label_d_pred=\"d_pred from starting model\", color_d_pred=\"black\")\n\n# plot the model and d_pred for true model\nplot_model_and_data(model=ref_good_model, label_model=\"reference good model\", color_model=\"red\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace, \n                    label_d_pred=\"d_pred from reference good model\", color_d_pred=\"red\", axes=axes)\n\n# plot the model and d_pred for inverted model, and d_obs\nplot_model_and_data(model=inv_result_sw_field.model, \n                    label_model=\"inverted model from field data\", color_model=\"green\",\n                    forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                    label_d_pred=\"d_pred from inverted model\", color_d_pred=\"green\", axes=axes)\n\n# plot randomly selected samples and data predictions from samples\nflat_samples = sampler.get_chain(discard=1000, thin=300, flat=True)\nrand_indices = np.random.randint(len(flat_samples), size=100)\nfor i, sample in enumerate(samples):\n    label_model = \"sample models\" if i == 0 else None\n    label_d_pred = \"d_pred from samples\" if i == 0 else None\n    plot_model_and_data(model=sample, label_model=label_model, color_model=\"gray\",\n                        forward_func=forward_sw_interp, periods=field_d_periods_logspace,\n                        label_d_pred=label_d_pred, color_d_pred=\"gray\", axes=axes, light_thin=True)\n\n# plot d_obs\nplot_data(field_d_obs, field_d_periods, ax=axes[1], scatter=True, color=\"orange\", s=8, label=\"d_obs\")\n\naxes[0].set_ylim(100, 0)\naxes[0].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\naxes[1].legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.46));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# Watermark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"numpy\", \"matplotlib\", \"scipy\", \"emcee\", \"bayesbay\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}