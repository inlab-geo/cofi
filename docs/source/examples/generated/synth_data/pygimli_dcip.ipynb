{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DCIP with PyGIMLi (Synthetic example)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/examples/pygimli_dcip/pygimli_dcip.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n<!-- Again, please don't touch the markdown cell above. We'll generate badge \n     automatically from the above cell. -->\n```\n```{=html}\n<!-- This cell describes things related to environment setup, so please add more text \n     if something special (not listed below) is needed to run this notebook -->\n```\n> If you are running this notebook locally, make sure you've followed\n> [steps\n> here](https://github.com/inlab-geo/cofi-examples#run-the-examples-with-cofi-locally)\n> to set up the environment. (This\n> [environment.yml](https://github.com/inlab-geo/cofi-examples/blob/main/envs/environment.yml)\n> file specifies a list of packages required to run the notebooks)\n\nUsing the DCIP (Direct Current, Induced Polarization) solver provided by\n[PyGIMLi](https://www.pygimli.org/), we use different `cofi` solvers to\nsolve the corresponding inverse problem.\n\nNote: This notebook is adapted from a PyGIMLi example: [Naive\ncomplex-valued electrical\ninversion](https://www.pygimli.org/_examples_auto/3_dc_and_ip/plot_07_simple_complex_inversion.html#sphx-glr-examples-auto-3-dc-and-ip-plot-07-simple-complex-inversion-py)\n\nThe key difference between ERT and DCIP as implemented in PyGIMLi is\nthat for DCIP resistivties are expressed as complex numbers with the\nreal part representing the resistivity and the phase angle presenting\nthe chargeability. This means that entries into the model vector and the\ndata vector are complex numbers and that DCIP inversions using PyGIMLI\nrely on the induced polarization field measurements being expressed in\nthe frequency domain.\n\nWhile `numpy.linalg.solve` is able to call the appropriate Lapack\nsubroutine for a complex linear system `cgesv` or `zcgesv`, other\nsolvers typically expect the model vector and data vector to be real.\nThis means that the complex system of equation needs to be transformed\ninto a real system of equations. Such a transformation needs to be\naccounted for in the user provided functions for the objective function,\nHessian and gradient; care must also be taken when transforming the data\ncovariance matrix.\n\nThe linear equation \\$ A x =b \\$ with the elements of $A$, $b$ and $x$\nbeing complex numbers can be rewritten using real numbers as follows\n\n$$\\begin{aligned}\n\\begin{pmatrix}A^r & -A^c \\\\A^c & A^r \\end{pmatrix}\n\\begin{pmatrix}\nx^r \\\\\nx^c \n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb^r \\\\\nb^c \n\\end{pmatrix},\n\\end{aligned}$$\n\nwith $b=( b_1^r+b_1^c i, b_2^r+b_2^c i,...,b_n^r+b_n^c i)$ being\nrewritten as $(b^r,b^c)$ with $b^r=(b_1^r,b_2^r,...,b_n^r)$ and\n$b^c=(b_1^c,b_2^c,...,b_n^c)$ and analogus reordering for $A$ and $x$.\n\nSee <https://ijpam.eu/contents/2012-76-1/11/11.pdf> for more details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------- #\n#                                                          #\n#     Uncomment below to set up environment on \"colab\"     #\n#                                                          #\n# -------------------------------------------------------- #\n\n# !pip install -U cofi\n\n# !pip install -q condacolab\n# import condacolab\n# condacolab.install()\n# !mamba install -c gimli pygimli=1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will need the following packages:\n\n-   `numpy` for matrices and matrix-related functions\n-   `matplotlib` for plotting\n-   `pygimli` for forward modelling of the problem\n-   `cofi` for accessing different inference solvers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport pygimli\nimport cofi\n\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we define a set of utility functions that help define the problem,\ngenerating data and making plots. Feel free to skip reading the details\nof these utility functions and come back later if you want.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.1. Helper functions for complex numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def rho_phi_to_complex(rho, phi):      # rho * e^(phi * i)\n    return pygimli.utils.toComplex(rho, phi)\n\ndef rho_phi_from_complex(complx):      # |complx|, arctan(complx.imag, complx.real)\n    return np.abs(complx), np.arctan2(complx.imag, complx.real)\n\ndef complex_to_real(complx):           # complx vector of size n -> size 2n\n    return pygimli.utils.squeezeComplex(complx)\n\ndef complex_from_real(real):           # real vector of size n -> size n/2\n    return pygimli.utils.toComplex(real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.2. Helper functions for PyGIMLi modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Utility Functions\nx_inv_start = -2\nx_inv_stop = 52\ny_inv_start = -20\ny_inv_stop = 0\n\ndef survey_scheme(start=0, stop=50, num=51, schemeName=\"dd\"):\n    scheme = pygimli.physics.ert.createData(elecs=np.linspace(start=start, stop=stop, num=num),schemeName=schemeName)\n    return scheme\n\ndef model_true(\n    scheme, \n    start=[-55, 0], \n    end=[105, -80], \n    anomalies_pos=[[10,-7],[40,-7]], \n    anomalies_rad=[5,5],\n    rhomap=[[1, rho_phi_to_complex(100, 0 / 1000)],\n          # Magnitude: 50 ohm m, Phase: -50 mrad\n          [2, rho_phi_to_complex(50, 0 / 1000)],\n          [3, rho_phi_to_complex(100, -50 / 1000)],]\n    ):\n    world = pygimli.meshtools.createWorld(start=start, end=end, worldMarker=True)\n    for s in scheme.sensors():          # local refinement \n        world.createNode(s + [0.0, -0.1])\n    geom = world\n    for i, (pos, rad) in enumerate(zip(anomalies_pos, anomalies_rad)):\n        anomaly = pygimli.meshtools.createCircle(pos=pos, radius=rad, marker=i+2)\n        geom += anomaly\n    mesh = pygimli.meshtools.createMesh(geom, quality=33)\n    return mesh, rhomap\n\ndef ert_simulate(mesh, scheme, rhomap, noise_level=1, noise_abs=1e-6):\n    pg_data = pygimli.physics.ert.simulate(mesh, scheme=scheme, res=rhomap, noiseLevel=noise_level,\n                        noise_abs=noise_abs, seed=42)\n    # data.remove(data[\"rhoa\"] < 0)\n    data_complex = rho_phi_to_complex(pg_data[\"rhoa\"].array(), pg_data[\"phia\"].array())\n    data_log_complex = np.log(data_complex)\n    return pg_data, data_complex, data_log_complex\n\ndef ert_manager(pg_data, verbose=False):\n    return pygimli.physics.ert.ERTManager(pg_data, verbose=verbose, useBert=True)\n\ndef inversion_mesh(ert_mgr):\n    inv_mesh = ert_mgr.createMesh(ert_mgr.data)\n    # print(\"model size\", inv_mesh.cellCount())   # 1031\n    ert_mgr.setMesh(inv_mesh)\n    return inv_mesh\n\ndef ert_forward_operator(ert_mgr, pg_data, inv_mesh):\n    forward_oprt = ert_mgr.fop\n    forward_oprt.setComplex(True)\n    forward_oprt.setData(pg_data)\n    forward_oprt.setMesh(inv_mesh, ignoreRegionManager=True)\n    return forward_oprt\n\ndef reg_matrix(forward_oprt):\n    region_manager = forward_oprt.regionManager()\n    region_manager.setConstraintType(2)\n    Wm = pygimli.matrix.SparseMapMatrix()\n    region_manager.fillConstraints(Wm)\n    Wm = pygimli.utils.sparseMatrix2coo(Wm)\n    return Wm\n\ndef starting_model(data, inv_mesh, rho_val=None, phi_val=None):\n    rho_start = np.median(data[\"rhoa\"]) if rho_val is None else rho_val\n    phi_start = np.median(data[\"phia\"]) if phi_val is None else phi_val\n    start_model_val = rho_phi_to_complex(rho_start, phi_start)\n    start_model_complex = np.ones(inv_mesh.cellCount()) * start_model_val\n    start_model_log_complex = np.log(start_model_complex)\n    start_model_log_real = complex_to_real(start_model_log_complex)\n    return start_model_complex, start_model_log_complex, start_model_log_real\n\ndef model_vector(rhomap, mesh):\n    return pygimli.solver.parseArgToArray(rhomap, mesh.cellCount(), mesh).array()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.3. Helper functions for plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_model(mesh, model_complex, title):\n    rho, phi = rho_phi_from_complex(model_complex)\n    fig, axes = plt.subplots(1,2,figsize=(10,3))\n    pygimli.show(mesh, data=rho, label=r\"$\\Omega m$\", ax=axes[0])\n    axes[0].set_xlim(x_inv_start, x_inv_stop)\n    axes[0].set_ylim(y_inv_start, y_inv_stop)\n    axes[0].set_title(\"Resistivity\")\n    pygimli.show(mesh, data=phi * 1000, label=r\"mrad\", ax=axes[1])\n    axes[1].set_xlim(x_inv_start, x_inv_stop)\n    axes[1].set_ylim(y_inv_start, y_inv_stop)\n    axes[1].set_title(\"Chargeability\")\n    fig.suptitle(title)\n\ndef plot_data(pg_data, data_complex, title):\n    rho, phi = rho_phi_from_complex(data_complex)\n    fig, axes = plt.subplots(1,2,figsize=(10,4))\n    pygimli.physics.ert.showERTData(pg_data, vals=rho, label=r\"$\\Omega$m\", ax=axes[0])\n    axes[0].set_title(\"Apparent Resistivity\")\n    pygimli.physics.ert.showERTData(pg_data, vals=phi*1000, label=r\"mrad\", ax=axes[1])\n    axes[1].set_title(\"Apparent Chargeability\")\n    fig.suptitle(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Define the problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first define the true model, the survey and map it on a computational\nmesh designed for the survey and true anomaly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.1. True model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# PyGIMLi - define measuring scheme, geometry, forward mesh and true model\nscheme = survey_scheme()\nmesh, rhomap = model_true(scheme)\n\n# plot the true model\nplot_model(mesh, model_vector(rhomap, mesh), \"True model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.2. Generate synthetic data\n\nGenerate the synthetic data as a container with all the necessary\ninformation for plotting:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pg_data, data_complex, data_log_complex = ert_simulate(mesh, scheme, rhomap)\n\nplot_data(pg_data, data_complex, \"(Synthetic) Data Observatons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3. ERTManager\n\nFurther, we create a `pygimli.ert.ERTManager` instance to keep record of\nproblem-specific information like the inversion mesh, and to perform\nforward operation for the inversion solvers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create PyGIMLi's ERT manager\nert_mgr = ert_manager(pg_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.4. Inversion mesh\n\nThe inversion can use a different mesh and the mesh to be used should\nknow nothing about the mesh that was designed based on the true model.\nHere we first use a triangular mesh for the inversion, which makes the\nproblem underdetermined.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_mesh = inversion_mesh(ert_mgr)\n\nax = pygimli.show(inv_mesh, showMesh=True, markers=False, colorBar=False)\nax[0].set_title(\"Mesh used for inversion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.5. Forward operator, regularization matrix\n\nWith the inversion mesh created, we now define a starting model, forward\noperator and weighting matrix for regularization using PyGIMLi.\n\nOur model will be in log space when we perform inversion (for numerical\nstability purposes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# PyGIMLi's forward operator (ERTModelling)\nforward_oprt = ert_forward_operator(ert_mgr, scheme, inv_mesh)\n\n# extract regularization matrix\nWm = reg_matrix(forward_oprt)\n\n# initialise a starting model for inversion\nstart_model, start_model_log, start_model_log_real = starting_model(pg_data, ert_mgr.paraDomain)\nplot_model(ert_mgr.paraDomain, start_model, \"Starting model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.6. Utility functions to pass to CoFI\n\nCoFI and other inference packages require a set of functions that\nprovide the misfit, the jacobian the residual within the case of scipy\nstandardised interfaces. All these functions are defined below as\nadditional utility functions, so feel free to read them into details if\nyou want to understand more. These functions are:\n\n-   `get_response`\n-   `get_jacobian`\n-   `get_residuals`\n-   `get_data_misfit`\n-   `get_regularization`\n-   `get_gradient`\n-   `get_hessian`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Utility Functions (additional)\n\ndef _ensure_numpy(model):\n    if \"torch.Tensor\" in str(type(model)):\n        model = model.cpu().detach().numpy()\n    return model\n\n# model_log_complex -> data_log_complex\ndef get_response(model_log_complex, fop):\n    model_complex = np.exp(model_log_complex)\n    model_real = complex_to_real(model_complex)\n    model_real = _ensure_numpy(model_real)\n    data_real = np.array(fop.response(model_real))\n    data_complex = complex_from_real(data_real)\n    data_log_complex = np.log(data_complex)\n    return data_log_complex\n\n# model_log_complex -> J_log_log_complex\ndef get_jacobian(model_log_complex, fop):\n    model_complex = np.exp(model_log_complex)\n    model_real = complex_to_real(model_complex)\n    model_real = _ensure_numpy(model_real)\n    J_block = fop.createJacobian(model_real)\n    J_real = np.array(J_block.mat(0))\n    J_imag = np.array(J_block.mat(1))\n    J_complex = J_real + 1j * J_imag\n    data_log_complex = get_response(model_log_complex, fop)\n    data_complex = np.exp(data_log_complex)\n    J_log_log_complex = J_complex / data_complex[:,np.newaxis] * model_complex[np.newaxis,:]\n    return J_log_log_complex\n\n# model_log_complex -> res_data_log_complex\ndef get_residuals(model_log_complex, data_log_complex, fop):\n    synth_data_log_complex = get_response(model_log_complex, fop)\n    return data_log_complex - synth_data_log_complex\n\n# model_log_real -> obj_log_real\ndef get_objective(model_log_real, data_log_complex, fop, lamda, Wm):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate data misfit\n    res_log_complex = get_residuals(model_log_complex, data_log_complex, fop)\n    data_misfit = res_log_complex.conj().dot(res_log_complex)\n    # calculate regularization term\n    weighted_model_log_real = Wm.dot(model_log_complex)\n    reg = lamda * weighted_model_log_real.conj().dot(weighted_model_log_real)\n    # sum up\n    result = np.abs(data_misfit + reg)\n    return result\n\n# model_log_real -> grad_log_real\ndef get_gradient(model_log_real, data_log_complex, fop, lamda, Wm):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate gradient for data misfit\n    res = get_residuals(model_log_complex, data_log_complex, fop)\n    jac = get_jacobian(model_log_complex, fop)\n    data_misfit_grad = - jac.conj().T.dot(res)\n    # calculate gradient for regularization term\n    reg_grad = lamda * Wm.T.dot(Wm).dot(model_log_complex)\n    # sum up\n    grad_complex = data_misfit_grad + reg_grad\n    grad_real = complex_to_real(grad_complex)\n    return grad_real\n\n# model_log_real -> hess_log_real\ndef get_hessian(model_log_real, data_log_complex, fop, lamda, Wm):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate hessian for data misfit\n    res = get_residuals(model_log_complex, data_log_complex, fop)\n    jac = get_jacobian(model_log_complex, fop)\n    data_misfit_hessian = jac.conj().T.dot(jac)\n    # calculate hessian for regularization term\n    reg_hessian = lamda * Wm.T.dot(Wm)\n    # sum up\n    hessian_complex = data_misfit_hessian + reg_hessian\n    nparams = len(model_log_complex)\n    hessian_real = np.zeros((2*nparams, 2*nparams))\n    hessian_real[:nparams,:nparams] = np.real(hessian_complex)\n    hessian_real[:nparams,nparams:] = -np.imag(hessian_complex)\n    hessian_real[nparams:,:nparams] = np.imag(hessian_complex)\n    hessian_real[nparams:,nparams:] = np.real(hessian_complex)\n    return hessian_real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With all the above forward operations set up with PyGIMLi, we now define\nthe problem in `cofi` by setting the problem information for a\n`BaseProblem` object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# hyperparameters\nlamda=0.001\n\n# CoFI - define BaseProblem\ndcip_problem = cofi.BaseProblem()\ndcip_problem.name = \"DC-IP defined through PyGIMLi\"\ndcip_problem.set_objective(get_objective, args=[data_log_complex, forward_oprt, lamda, Wm])\ndcip_problem.set_gradient(get_gradient, args=[data_log_complex, forward_oprt, lamda, Wm])\ndcip_problem.set_hessian(get_hessian, args=[data_log_complex, forward_oprt, lamda, Wm])\ndcip_problem.set_initial_model(start_model_log_real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Define the inversion options and run\n\n## 3.1. SciPy's optimizer (trust-ncg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dcip_problem.suggest_tools();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_scipy = cofi.InversionOptions()\ninv_options_scipy.set_tool(\"scipy.optimize.minimize\")\ninv_options_scipy.set_params(method=\"trust-ncg\", options={\"maxiter\":5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_scipy = cofi.Inversion(dcip_problem, inv_options_scipy)\ninv_result_scipy = inv_scipy.run()\nprint(f\"\\nSolver message: {inv_result_scipy.message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_scipy = np.exp(complex_from_real(inv_result_scipy.model))\nplot_model(ert_mgr.paraDomain, model_scipy, \"Inferred model (scipy's trust-ncg)\")\n\nsynth_data_scipy = np.exp(get_response(np.log(model_scipy), forward_oprt))\nplot_data(pg_data, synth_data_scipy, \"Inferred model produced data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.2. PyTorch's optimizer (RAdam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_torch = cofi.InversionOptions()\ninv_options_torch.set_tool(\"torch.optim\")\ninv_options_torch.set_params(algorithm=\"RAdam\", lr=0.05, num_iterations=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_torch = cofi.Inversion(dcip_problem, inv_options_torch)\ninv_result_torch = inv_torch.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_torch = np.exp(complex_from_real(inv_result_torch.model))\nplot_model(ert_mgr.paraDomain, model_torch, \"Inferred model (torch.optim.RAdam)\")\n\nsynth_data_torch = np.exp(get_response(np.log(model_torch), forward_oprt))\nplot_data(pg_data, synth_data_torch, \"Inferred model produced data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# Watermark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"numpy\", \"scipy\", \"pygimli\", \"torch\", \"matplotlib\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}