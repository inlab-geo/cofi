{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Century DCIP Inversion with a Triangular Mesh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/examples/pygimli_dcip/pygimli_dcip_century_tri_mesh.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n<!-- Again, please don't touch the markdown cell above. We'll generate badge \n     automatically from the above cell. -->\n```\n```{=html}\n<!-- This cell describes things related to environment setup, so please add more text \n     if something special (not listed below) is needed to run this notebook -->\n```\n> If you are running this notebook locally, make sure you've followed\n> [steps\n> here](https://github.com/inlab-geo/cofi-examples#run-the-examples-with-cofi-locally)\n> to set up the environment. (This\n> [environment.yml](https://github.com/inlab-geo/cofi-examples/blob/main/envs/environment.yml)\n> file specifies a list of packages required to run the notebooks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Motivation\n\nThe Century Deposit is a zinc-lead-silver deposit in the Mt Isa region\nin Queensland Australia and UBC 2D DCIP inversion results have been\npublished by [Mutton, 2000](https://doi.org/10.1190/1.1444878) and\nreproduced with\n[SimPEG](https://curvenote.com/@simpeg/transform-2020-simpeg-tutorial/!6DDumb03Le6D8N8xuJNs).\nIt provides an excellent test case to verify if CoFI can indeed act as a\nglue between forward solvers and inverse solvers and be applied to real\ndata. [Figure\n1](https://github.com/inlab-geo/cofi-examples/blob/main/examples/pygimli_dcip/Mutton-Figure1-1.png?raw=true)\nfrom [Mutton, 2000](https://doi.org/10.1190/1.1444878) provides a map of\nthe location and geological setting for the Century deposit.\n\nA detailed descrtiption of the geological setting is available\n[here](http://portergeo.com.au/database/mineinfo.asp?mineid=mn075) and\n[Mutton, 2000](https://doi.org/10.1190/1.1444878) also provide the\n[cross-section](https://github.com/inlab-geo/cofi-examples/blob/main/examples/pygimli_dcip/Mutton-Figure2-1.png?raw=true)\nfor the survey line 46800mE, which we will invert in the following.\n\nWhat we are interested in is delineating the mineralised units by using\nthe DCIP (Direct Current, Induced Polarization) solver implemented in\n[PyGIMLi](https://www.pygimli.org/) together with the `cofi` solvers.\n\nSome background information around how a DCIP inversion using complex\nnumbers to express resistivity and chargeability can be implemented\nusing CoFI is given in [the synthetic example\nnotebook](pygimli_dcip.ipynb). While PyGIMLi allows us to use a\ntriangular mesh which can be adanvatengous when compared with a\nrectilinear mesh, it also requires the data and model to be expressed as\nfrequency domain measurements, that is as complex numbers where the real\npart represents the resistivity and the phase angle the chargeability.\nThere are several ways to [capture/express\nchargeability](https://gpg.geosci.xyz/content/induced_polarization/induced_polarization_data.html)\nand SimPEG uses apparent chargeabilities $\\mathrm{M}$. Thus prior to\ninversion we will convert them using the following rule of thumb\n$0.1 M \\approx70 \\mathrm{mrad}$.\n\n## References\n\nMartin, T., G\u00fcnther, T., Orozco, A. F., & Dahlin, T. (2020). Evaluation\nof spectral induced polarization field measurements in time and\nfrequency domain. Journal of Applied Geophysics, 180.\n<https://doi.org/10.1016/j.jappgeo.2020.104141>\n\nMutton, A. J. (2000). The application of geophysics during evaluation of\nthe Century zinc deposit. Geophysics, 65(6), 1946--1960.\n<https://doi.org/10.1190/1.1444878>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Set up environment\n\nWe'll do the following: 1. Install PyGIMLi (if on CoLab) 2. Download\nprocessed dataset (if on CoLab) 3. Import modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------- #\n#                                                          #\n#     Uncomment below to set up environment on \"colab\"     #\n#                                                          #\n# -------------------------------------------------------- #\n\n# !pip install -U cofi pygimli tetgen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------- #\n#                                                          #\n#     Uncomment below to set up environment on \"colab\"     #\n#                                                          #\n# -------------------------------------------------------- #\n\n# !git clone https://github.com/inlab-geo/cofi-examples.git\n# %cd cofi-examples/examples/pygimli_dcip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will need the following packages:\n\n-   `os` to list and load dataset\n-   `numpy` for matrices and matrix-related functions\n-   `matplotlib` for plotting\n-   `pygimli` for forward modelling of the problem\n-   `cofi` for accessing different inference solvers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pygimli\nimport cofi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Load the data\n\nWe will need to download the preprocessed dataset first. This notebook\n[century_data_preprocessing.ipynb](century_data_preprocessing.ipynb)\ncontains the code for data preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_base_path = \"../../data/century_dcip\"\ndcip_data = np.loadtxt(f\"{data_base_path}/century_dcip_data.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Converting measurements of chargeability\n\nPyGIMLi expresses chargeability in $\\mathrm{radians}$ and we convert the\napparent chargeabilites as we load the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a_locs = dcip_data[:,0]\nb_locs = dcip_data[:,1]\nm_locs = dcip_data[:,2]\nn_locs = dcip_data[:,3]\ndc_obs = dcip_data[:,4]\ndc_err = dcip_data[:,5]\nip_obs = dcip_data[:,6]*0.7   # https://gpg.geosci.xyz/content/induced_polarization/induced_polarization_data.html\nip_err = dcip_data[:,7]*0.7\ngeo_factors = dcip_data[:,8]\n\nlocation_start = np.min(a_locs)\nlocation_stop = np.max(n_locs)\nlocation_interval = m_locs[1] - m_locs[0]\nlocation_num = int((location_stop - location_start) / location_interval + 1)\n\nlocation_start, location_stop, location_interval, location_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_leapfrog_geologic_section(filename=f\"{data_base_path}/century_geologic_section.csv\"):\n    \"\"\"\n    Load the geologic cross section. \n    \"\"\"\n    fid = open(filename, 'r')\n    lines = fid.readlines()\n    data = []\n    data_tmp = []\n    for line in lines[2:]:\n        line_data = (line.split(',')[:3])\n        if 'End' in line:\n            data.append(np.vstack(data_tmp)[:,[0, 2]])\n            data_tmp = []\n        else:\n            data_tmp.append(np.array(line_data, dtype=float))\n    return data\n\ngeologic_section = load_leapfrog_geologic_section()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Utility wrappers to PyGIMLi functions\n\nBelow we define a set of utility functions that help define the problem,\ngenerating data and making plots. Feel free to skip reading the details\nof these utility functions and come back later if you want.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.1. Helper functions for complex numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def rho_phi_to_complex(rho, phi):      # rho * e^(phi * i)\n    return pygimli.utils.toComplex(rho, phi)\n\ndef rho_phi_from_complex(complx):      # |complx|, arctan(complx.imag, complx.real)\n    return np.abs(complx), np.arctan2(complx.imag, complx.real)\n\ndef complex_to_real(complx):           # complx vector of size n -> size 2n\n    return pygimli.utils.squeezeComplex(complx)\n\ndef complex_from_real(real):           # real vector of size n -> size n/2\n    return pygimli.utils.toComplex(real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.2. Helper functions for PyGIMLi modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# inversion mesh bound\nx_inv_start = location_start - 200\nx_inv_stop = location_stop + 200\ny_inv_start = -400\ny_inv_stop = 0\n\n# PyGIMLi DataContainerERT\ndef pygimli_data(a_locs, b_locs, m_locs, n_locs, dc_obs, dc_err, ip_obs, ip_err):\n    # --- create empty data container object ---\n    pg_data = pygimli.DataContainerERT()\n    # create sensor locations\n    for sensor in np.linspace(location_start, location_stop, location_num):\n        pg_data.createSensor((sensor, 0.0, 0.0))\n    # --- add indices for data points ---\n    locs_sources = np.vstack((a_locs, b_locs)).T\n    locs_receivers = np.vstack((m_locs, n_locs)).T\n    for i in range(len(locs_sources)):\n        src = locs_sources[i]\n        src_idx = (src - location_start) / location_interval\n        rec = locs_receivers[i]\n        rec_idx = (rec - location_start) / location_interval\n        pg_data.createFourPointData(i, src_idx[0], src_idx[1], rec_idx[0], rec_idx[1])\n    # --- fill in the observed data and error estimation ---\n    pg_data[\"rhoa\"] = dc_obs\n    pg_data[\"err\"] = dc_err\n    pg_data[\"phia\"] = -ip_obs/1000.  # PyGIMLi accepts radians (instead of milliradians) for forward modelling\n    pg_data[\"iperr\"] = ip_err/1000.\n    # --- create geometric factor k ---\n    pg_data[\"k\"] = pygimli.physics.ert.createGeometricFactors(pg_data, numerical=True)\n    # --- generate data vals and diag vals of covariance inv matrix in log complex space ---\n    data_complex = rho_phi_to_complex(pg_data[\"rhoa\"].array(), pg_data[\"phia\"].array())\n    data_log_complex = np.log(data_complex)\n    dc_err_log = np.log(pg_data[\"err\"])\n    ip_err_log = np.log(pg_data[\"iperr\"])\n    m_err = rho_phi_to_complex(1/dc_err_log, 1/ip_err_log)\n    Wd = np.diag(m_err)\n    Cd_inv = Wd.conj().dot(Wd)\n    return pg_data, data_log_complex, Cd_inv\n\n# PyGIMLi ert.ERTManager\ndef ert_manager(pg_data, verbose=False):\n    return pygimli.physics.ert.ERTManager(pg_data, verbose=verbose, useBert=True)\n\n# mesh used for inversion\ndef inversion_mesh(ert_mgr):\n    inv_mesh = ert_mgr.createMesh(ert_mgr.data)\n    inv_mesh = inv_mesh.createH2()\n    ert_mgr.setMesh(inv_mesh)\n    print(\"model size\", ert_mgr.paraDomain.cellCount())\n    return inv_mesh\n\n# mesh used for the original paper\ndef inversion_mesh_ubc(ert_mgr):\n    mesh_ubc = pygimli.meshtools.readMeshIO(f\"{data_base_path}/century_mesh.vtk\")\n    print(\"model size\", mesh_ubc.cellCount())\n    ert_mgr.setMesh(mesh_ubc)\n    return mesh_ubc\n\n# PyGIMLi ert.ERTModelling\ndef ert_forward_operator(ert_mgr, pg_data, inv_mesh):\n    forward_oprt = ert_mgr.fop\n    forward_oprt.setComplex(True)\n    forward_oprt.setData(pg_data)\n    forward_oprt.setMesh(inv_mesh, ignoreRegionManager=True)\n    return forward_oprt\n\n# regularization matrix\ndef reg_matrix(forward_oprt, inv_mesh):\n    region_manager = forward_oprt.regionManager()\n    region_manager.setConstraintType(2)\n    region_manager.setMesh(inv_mesh)\n    Wm = pygimli.matrix.SparseMapMatrix()\n    region_manager.fillConstraints(Wm)\n    Wm = pygimli.utils.sparseMatrix2coo(Wm)\n    return Wm\n\ndef starting_model(data, inv_mesh, rho_val=None, phi_val=None):\n    rho_start = np.median(data[\"rhoa\"]) if rho_val is None else rho_val\n    phi_start = np.median(data[\"phia\"]) if phi_val is None else phi_val\n    start_model_val = rho_phi_to_complex(rho_start, phi_start)\n    start_model_complex = np.ones(inv_mesh.cellCount()) * start_model_val\n    start_model_log_complex = np.log(start_model_complex)\n    start_model_log_real = complex_to_real(start_model_log_complex)\n    return start_model_complex, start_model_log_complex, start_model_log_real\n\ndef reference_dc_model():\n    return np.loadtxt(f\"{data_base_path}/century_dc_model.txt\")\n\ndef reference_ip_model():\n    return -np.loadtxt(f\"{data_base_path}/century_ip_model.txt\") * 0.7 / 1000\n\n# initialise model to have same resistivities as the original inversion result\ndef starting_model_ref(ert_mgr):\n    dc_model_ref = np.loadtxt(f\"{data_base_path}/century_dc_model.txt\")\n    assert ert_mgr.paraDomain.cellCount() == len(dc_model_ref), \\\n        \"mesh cell count has to match century reference model length\"\n    return starting_model(ert_mgr, rhoa_val=dc_model_ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.3. Plotting utilities\n\nNote: We lifted out the plotting of colorbars only for Colab\ncompatibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resistivity_label = r\"$\\Omega m$\"\nchargeability_label = r\"mrad\"\n\ndef plot_geologic_section(geologic_section, ax):\n    for data in geologic_section:\n        ax.plot(data[:,0], data[:,1], 'k--', alpha=0.5)\n\ndef plot_colorbar(ax, cMin, cMax, label, orientation=\"horizontal\"):\n    norm = mpl.colors.Normalize(cMin, cMax)\n    sm = plt.cm.ScalarMappable(norm=norm)\n    cb = plt.colorbar(sm, orientation=orientation, ax=ax)\n    cb.set_label(label)\n    cb.set_ticks(np.linspace(cMin, cMax, 5, endpoint=True))\n\ndef plot_model(mesh, model_complex, title):\n    rho, phi = rho_phi_from_complex(model_complex)\n    fig, axes = plt.subplots(2,1,figsize=(12,5))\n    pygimli.show(mesh, data=rho, label=resistivity_label, ax=axes[0], colorBar=False)\n    axes[0].set_xlim(x_inv_start, x_inv_stop)\n    axes[0].set_ylim(y_inv_start, y_inv_stop)\n    axes[0].set_title(\"Resistivity\")\n    plot_colorbar(axes[0], 136, 170, resistivity_label)\n    pygimli.show(mesh, data=phi * 1000, label=chargeability_label, cMin=-4.76, cMax=-4, ax=axes[1], colorBar=False)\n    axes[1].set_xlim(x_inv_start, x_inv_stop)\n    axes[1].set_ylim(y_inv_start, y_inv_stop)\n    axes[1].set_title(\"Chargeability\")\n    plot_colorbar(axes[1], -4.76, -4, chargeability_label)\n    if title != \"Starting model\":\n        plot_geologic_section(geologic_section, axes[0])\n        plot_geologic_section(geologic_section, axes[1])\n    fig.suptitle(title)\n\ndef plot_data(pg_data, data_complex, title):\n    rho, phi = rho_phi_from_complex(data_complex)\n    fig, axes = plt.subplots(1,2,figsize=(10,4))\n    # pygimli.physics.ert.showERTData(pg_data, vals=rho, label=resistivity_label, ax=axes[0], colorBar=False)\n    pygimli.physics.ert.showERTData(pg_data, vals=rho, ax=axes[0], colorBar=False)\n    axes[0].set_title(\"Apparent Resistivity\")\n    plot_colorbar(axes[0], np.min(rho), np.max(rho), resistivity_label)\n    pygimli.physics.ert.showERTData(pg_data, vals=phi*1000, ax=axes[1], colorBar=False)\n    # pygimli.physics.ert.showERTData(pg_data, vals=phi*1000, label=chargeability_label, ax=axes[1], colorBar=False)\n    axes[1].set_title(\"Apparent Chargeability\")\n    plot_colorbar(axes[1], np.min(phi*1000), np.max(phi*1000), chargeability_label)\n    fig.suptitle(title)\n\ndef plot_mesh(mesh, title=\"Mesh used for inversion\"):\n    _, ax = plt.subplots(1, 1)\n    pygimli.show(mesh, showMesh=True, markers=False, colorBar=False, ax=ax)\n    ax.set_title(title)\n    ax.set_xlabel(\"Northing (m)\")\n    ax.set_ylabel(\"Elevation (m)\")\n\ndef plot_comparison(mesh1, model1, title1, mesh2, model2, title2, rho_min, rho_max, phi_min, phi_max):\n    rho1, phi1 = rho_phi_from_complex(model1)\n    rho2, phi2 = rho_phi_from_complex(model2)\n    fig, axes = plt.subplots(4, 1, figsize=(10,12))\n    pygimli.show(mesh1, data=rho1, label=resistivity_label, ax=axes[0], colorBar=False)\n    axes[0].set_xlim(x_inv_start, x_inv_stop)\n    axes[0].set_ylim(y_inv_start, y_inv_stop)\n    axes[0].set_title(f\"{title1} - Resistivity\")\n    plot_colorbar(axes[0], rho_min, rho_max, resistivity_label)\n    plot_geologic_section(geologic_section, axes[0])\n    pygimli.show(mesh2, data=rho2, label=resistivity_label, ax=axes[1], cMin=rho_min, cMax=rho_max, colorBar=False)\n    axes[1].set_xlim(x_inv_start, x_inv_stop)\n    axes[1].set_ylim(y_inv_start, y_inv_stop)\n    axes[1].set_title(f\"{title2} - Resistivity\")\n    plot_colorbar(axes[1], rho_min, rho_max, resistivity_label)\n    plot_geologic_section(geologic_section, axes[1])\n    pygimli.show(mesh1, data=phi1 * 1000, label=chargeability_label, ax=axes[2], colorBar=False)\n    axes[2].set_xlim(x_inv_start, x_inv_stop)\n    axes[2].set_ylim(y_inv_start, y_inv_stop)\n    axes[2].set_title(f\"{title1} - Chargeability\")\n    plot_colorbar(axes[2], phi_min*1000, phi_max*1000, chargeability_label)\n    plot_geologic_section(geologic_section, axes[2])\n    pygimli.show(mesh2, data=phi2 * 1000, label=chargeability_label, ax=axes[3], cMin=phi_min*1000, cMax=phi_max*1000, colorBar=False)\n    axes[3].set_xlim(x_inv_start, x_inv_stop)\n    axes[3].set_ylim(y_inv_start, y_inv_stop)\n    axes[3].set_title(f\"{title2} - Chargeability\")\n    plot_colorbar(axes[3], phi_min*1000, phi_max*1000, chargeability_label)\n    plot_geologic_section(geologic_section, axes[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. PyGIMLi problem setup\n\n## 4.1. Data container\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pg_data, data_log_complex, Cd_inv = pygimli_data(a_locs, b_locs, m_locs, n_locs, dc_obs, dc_err, ip_obs, ip_err)\npg_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# this cell needs to be run twice in order to work well\nplot_data(pg_data, np.exp(data_log_complex), \"Data Observatons\")\nplot_data(pg_data, np.diag(Cd_inv), \"Data covariance inverse weighting in log space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.2. ERT manager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ert_mgr = ert_manager(pg_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.3. Inversion mesh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_mesh = inversion_mesh(ert_mgr)\n# inv_mesh = inversion_mesh_ubc(ert_mgr)\n\nplot_mesh(inv_mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.4. Forward operator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forward_oprt = ert_forward_operator(ert_mgr, pg_data, ert_mgr.paraDomain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.5. Regularization matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Wm = reg_matrix(forward_oprt, ert_mgr.paraDomain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.6. Starting model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_model_complex, start_model_log_complex, start_model_log_real = starting_model(pg_data, ert_mgr.paraDomain)\n\nplot_model(ert_mgr.paraDomain, start_model_complex, \"Starting model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Create utility functions to pass to CoFI\n\nCoFI and other inference packages require a set of functions that\nprovide the misfit, the jacobian the residual within the case of scipy\nstandardised interfaces. All these functions are defined below as\nadditional utility functions, so feel free to read them into details if\nyou want to understand more. These functions are:\n\n-   `get_response`\n-   `get_jacobian`\n-   `get_residuals`\n-   `get_data_misfit`\n-   `get_regularization`\n-   `get_gradient`\n-   `get_hessian`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Utility Functions (additional)\n\ndef _ensure_numpy(model):\n    if \"torch.Tensor\" in str(type(model)):\n        model = model.cpu().detach().numpy()\n    return model\n\n# model_log_complex -> data_log_complex\ndef get_response(model_log_complex, fop):\n    model_complex = np.exp(model_log_complex)\n    model_real = complex_to_real(model_complex)\n    model_real = _ensure_numpy(model_real)\n    data_real = np.array(fop.response(model_real))\n    data_complex = complex_from_real(data_real)\n    data_log_complex = np.log(data_complex)\n    return data_log_complex\n\n# model_log_complex -> J_log_log_complex\ndef get_jacobian(model_log_complex, fop):\n    model_complex = np.exp(model_log_complex)\n    model_real = complex_to_real(model_complex)\n    model_real = _ensure_numpy(model_real)\n    J_block = fop.createJacobian(model_real)\n    J_real = np.array(J_block.mat(0))\n    J_imag = np.array(J_block.mat(1))\n    J_complex = J_real + 1j * J_imag\n    data_log_complex = get_response(model_log_complex, fop)\n    data_complex = np.exp(data_log_complex)\n    J_log_log_complex = J_complex / data_complex[:,np.newaxis] * model_complex[np.newaxis,:]\n    return J_log_log_complex\n\n# model_log_complex -> res_data_log_complex\ndef get_residuals(model_log_complex, data_log_complex, fop):\n    synth_data_log_complex = get_response(model_log_complex, fop)\n    return data_log_complex - synth_data_log_complex\n\n# model_log_real -> obj_log_real\ndef get_objective(model_log_real, data_log_complex, fop, lamda, Wm, Cd_inv):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate data misfit\n    res_log_complex = get_residuals(model_log_complex, data_log_complex, fop)\n    data_misfit = res_log_complex.conj().dot(Cd_inv).dot(res_log_complex)\n    # calculate regularization term\n    weighted_model_log_real = Wm.dot(model_log_complex)\n    reg = lamda * weighted_model_log_real.conj().dot(weighted_model_log_real)\n    # sum up\n    print(f\"data misfit: {np.abs(data_misfit)}, reg: {np.abs(reg)}\")\n    result = np.abs(data_misfit + reg)\n    return result\n\n# model_log_real -> grad_log_real\ndef get_gradient(model_log_real, data_log_complex, fop, lamda, Wm, Cd_inv):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate gradient for data misfit\n    res = get_residuals(model_log_complex, data_log_complex, fop)\n    jac = get_jacobian(model_log_complex, fop)\n    data_misfit_grad = - jac.conj().T.dot(Cd_inv).dot(res)\n    # calculate gradient for regularization term\n    reg_grad = lamda * Wm.T.dot(Wm).dot(model_log_complex)\n    # sum up\n    grad_complex = data_misfit_grad + reg_grad\n    grad_real = complex_to_real(grad_complex)\n    return grad_real\n\n# model_log_real -> hess_log_real\ndef get_hessian(model_log_real, data_log_complex, fop, lamda, Wm, Cd_inv):\n    # convert model_log_real into complex numbers\n    model_log_complex = complex_from_real(model_log_real)\n    # calculate hessian for data misfit\n    res = get_residuals(model_log_complex, data_log_complex, fop)\n    jac = get_jacobian(model_log_complex, fop)\n    data_misfit_hessian = jac.conj().T.dot(Cd_inv).dot(jac)\n    # calculate hessian for regularization term\n    reg_hessian = lamda * Wm.T.dot(Wm)\n    # sum up\n    hessian_complex = data_misfit_hessian + reg_hessian\n    nparams = len(model_log_complex)\n    hessian_real = np.zeros((2*nparams, 2*nparams))\n    hessian_real[:nparams,:nparams] = np.real(hessian_complex)\n    hessian_real[:nparams,nparams:] = -np.imag(hessian_complex)\n    hessian_real[nparams:,:nparams] = np.imag(hessian_complex)\n    hessian_real[nparams:,nparams:] = np.real(hessian_complex)\n    return hessian_real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# test\ntry:\n    get_response(start_model_log_real, forward_oprt)\nexcept RuntimeError:\n    print(\"run again\")\n    get_response(start_model_log_real, forward_oprt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# test\nobj_val = get_objective(start_model_log_real, data_log_complex, forward_oprt, 0.0001, Wm, Cd_inv)\nobj_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# test\ngradient = get_gradient(start_model_log_real, data_log_complex, forward_oprt, 0.0001, Wm, Cd_inv)\ngradient.shape, gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# test\nhessian = get_hessian(start_model_log_real, data_log_complex, forward_oprt, 0.0001, Wm, Cd_inv)\nhessian.shape, hessian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With all the above forward operations set up with PyGIMLi, we now define\nthe problem in `cofi` by setting the problem information for a\n`BaseProblem` object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# hyperparameters\nlamda=0.001\n\n# CoFI - define BaseProblem\ndcip_problem = cofi.BaseProblem()\ndcip_problem.name = \"DC-IP defined through PyGIMLi\"\ndcip_problem.set_objective(get_objective, args=[data_log_complex, forward_oprt, lamda, Wm, Cd_inv])\ndcip_problem.set_gradient(get_gradient, args=[data_log_complex, forward_oprt, lamda, Wm, Cd_inv])\ndcip_problem.set_hessian(get_hessian, args=[data_log_complex, forward_oprt, lamda, Wm, Cd_inv])\ndcip_problem.set_initial_model(start_model_log_real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Define the inversion options and run\n\nTriangular mesh solved with SciPy's optimizer (trust-ncg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options_scipy = cofi.InversionOptions()\ninv_options_scipy.set_tool(\"scipy.optimize.minimize\")\n\nclass CallBack:\n    def __init__(self):\n        self._i = 1\n    def __call__(self, x):\n        print(f\"Iteration #{self._i}, objective value: {dcip_problem.objective(x)}\")\n        self._i += 1\n        \ninv_options_scipy.set_params(method=\"trust-ncg\", options={\"maxiter\":10}, callback=CallBack())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_scipy = cofi.Inversion(dcip_problem, inv_options_scipy)\ninv_result_scipy = inv_scipy.run()\nprint(f\"\\nSolver message: {inv_result_scipy.message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_scipy = np.exp(complex_from_real(inv_result_scipy.model))\n# plot_model(inv_mesh, model_scipy, \"Inferred model (scipy's trust-ncg)\")\n\nsynth_data_scipy = np.exp(get_response(np.log(model_scipy), forward_oprt))\n# plot_data(pg_data, synth_data_scipy, \"Inferred model produced data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparison with published results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ref_dc = reference_dc_model()\nmodel_ref_ip = reference_ip_model()\nmodel_ref = rho_phi_to_complex(model_ref_dc, model_ref_ip)\nmesh_ref_x = np.loadtxt(f\"{data_base_path}/century_mesh_nodes_x.txt\")\nmesh_ref_z = np.loadtxt(f\"{data_base_path}/century_mesh_nodes_z.txt\")\nmesh_ref = pygimli.meshtools.createMesh2D(mesh_ref_x, mesh_ref_z)\nplot_comparison(mesh_ref, \n                model_ref, \n                \"Mutton A. J. (2000).\", \n                ert_mgr.paraDomain, \n                model_scipy, \n                \"Inference result\", \n                np.min(model_ref_dc), \n                np.max(model_ref_dc),\n                np.min(model_ref_ip), \n                np.max(model_ref_ip),\n               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The use of an adaptive triangular mesh means that we use fewer model\nparameters when compared with the original example and that our mesh is\nreflective of the underlying physics. This speeds up the forward problem\nand in turn means that the inverse problem is less under-determined and\na simpler regularisation (i.e.\u00a0smoothing) in a single stage inversion is\nsufficient to obtain a result that compares favorably with the original\nsolution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Model size in the original Mutton paper:\", mesh_ref.cellCount())\nprint(\"Model size of our model:\", ert_mgr.paraDomain.cellCount())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# Watermark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"numpy\", \"scipy\", \"pygimli\", \"torch\", \"matplotlib\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}