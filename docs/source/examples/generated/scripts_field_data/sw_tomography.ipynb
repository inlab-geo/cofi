{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Surface-Wave Tomography\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In\nColab](https://img.shields.io/badge/open%20in-Colab-b5e2fa?logo=googlecolab&style=flat-square&color=ffd670)](https://colab.research.google.com/github/inlab-geo/cofi-examples/blob/main/examples/sw_tomography/sw_tomography.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running this notebook locally, make sure you've followed\n[steps\nhere](https://github.com/inlab-geo/cofi-examples#run-the-examples-with-cofi-locally)\nto set up the environment. (This\n[environment.yml](https://github.com/inlab-geo/cofi-examples/blob/main/envs/environment.yml)\nfile specifies a list of packages required to run the notebooks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Theoretical Background\n\nWe assume surface waves propagate, from a given point on the Earth's\nsurface to another, without deviating from the great-circle path\nconnecting them. Under this assumption, the travel time between these\ntwo points is $t = \\int_{\\mathrm{path}}{s(\\phi(l), \\theta(l)) dl}$,\nwhere $\\phi$ and $\\theta$ denote longitude and latitude, and $s$ the\nEarth's slowness.\n\nIf we discretize the Earth's surface through $n$ blocks (or grid cells)\nof constant slowness, the forward equation for the average slowness\nassociated with the $i$th station pair reads `\\begin{equation}\n\\tag{1}\ns_i = \\frac{1}{L_i} \\sum_{j}^n {s_j l_j},\n\\end{equation}`{.interpreted-text role=\"raw-latex\"} where $L_i$ denotes\nthe great-circle distance and $\\frac{l_j}{L_i}$ the fraction of the\ngreat-circle path crossing the $j$th block. By defining the $m \\times n$\nmatrix such that $A_{ij} = \\frac{l_j}{L_i}$, we can switch to matrix\nnotation and write\n\n`\\begin{equation}\n\\tag{2}\n{\\bf A \\cdot x} = {\\bf d},\n\\end{equation}`{.interpreted-text role=\"raw-latex\"}\n\nwhere $\\bf d$ is the $m$-vector whose $i$th entry corresponds to the\nmeasured inter-station slowness, and $\\bf x$ the sought $n$-vector whose\n$j$th element corresponds to the model coefficient $s_j$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data and Imports\n\nIn this notebook, we utilize CoFI to estimate lateral variations in\nRayleigh-wave velocity across Australia at the surface-wave period of 5\ns. We use the data set collected by [Magrini et\nal.\u00a0(2023)](https://doi.org/10.1029/2023JB026688), consisting of 15,661\nmeasurements of average inter-station phase-velocity. These data, along\nwith the data kernel $\\mathbf{A}$ corresponding to a fine discretization\nof Australia consisting of 11,916 pixels of\n$0.3^\\circ \\times 0.3^\\circ$, are imported in this notebook through the\nSurfaceWaveTomography class of the\n[Espresso](https://github.com/inlab-geo/espresso) library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --------------------------------------------------------\n\n# Uncomment below to set up environment on \"colab\" {#section-1}\n\n# --------------------------------------------------------[]{#section-2} {#section-3}\n\n# !pip install -U cofi geo-espresso seislib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport scipy\n\nimport bayesbay as bb\nfrom espresso import SurfaceWaveTomography\nimport cofi\n\n# Imports for plotting\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import ScalarMappable\nfrom matplotlib.patches import PathPatch\nimport matplotlib.tri as tri\nimport cartopy.crs as ccrs\nfrom cartopy.mpl.patch import geos_to_path\n\nfrom shapely import Polygon, Point, box\nfrom seislib.tomography import EqualAreaGrid\nfrom seislib.utils import scatter_to_mesh\nfrom seislib.plotting import make_colorbar, scientific_label\nfrom seislib.plotting import plot_map as _plot_map\nimport seislib.colormaps as scm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "espresso_dict = SurfaceWaveTomography(example_number=3).example_dict\ngrid = espresso_dict['grid']\ngrid_points = np.column_stack(grid.midpoints_lon_lat())\nA = espresso_dict['jacobian']\npolygon = Polygon(espresso_dict['polygon'])\n\nd_obs = 1000 * espresso_dict['slowness']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Approach I: Regularized Least-Squares\n\nSince the $15661 \\times 11916$ matrix $\\mathbf{A}$ is not invertible,\nthe system of linear equations (2) is ill-conditioned and it is not\npossible to find an exact solution for $\\bf x$. In this section, we\novercome this issue by inverting for the regularized least-squares\nsolution\n\n`\\begin{equation}\n\\tag{3}\n{\\bf x} = {\\bf x}_0 + \\left( {\\bf A}^T \\cdot {\\bf A} + \\mu^2 {\\bf R}^T \\cdot {\\bf R} \\right)^{-1} \\cdot {\\bf A}^T \\cdot ({\\bf d}_{\\mathrm{obs}} - {\\bf A} \\cdot {\\bf x}_0),\n\\end{equation}`{.interpreted-text role=\"raw-latex\"} where we assumed\nthat the target slowness model is approximately known,\ni.e.\u00a0${\\bf x}_0 \\sim \\bf{x}$. In the above expression, the roughness\noperator $\\bf R$ depends on the discretization and the damping\ncoefficient $\\mu$ should be chosen via L-curve analysis. For technical\ndetails about the computation of $\\bf R$, see [Magrini et\nal.\u00a0(2022)](https://doi.org/10.1093/gji/ggac236).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x0 = np.full(A.shape[1], 1 / 3.0) # Starting model\nr = d_obs - A @ x0 # residuals\nR = espresso_dict['roughness_operator']\n# regularization = cofi.utils.QuadraticReg(np.array(R.todense()), (A.shape[1],))\nregularization = cofi.utils.QuadraticReg(R, (A.shape[1],))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoFI Problem and Options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_cofi_problem_least_squares(mu):\n    global A, R, r\n\n    problem = cofi.BaseProblem()\n    problem.set_data(r) # our data are now the residuals defined above\n    problem.set_jacobian(A)\n    problem.set_regularization(mu * regularization, mu * regularization.matrix)   # L2 norm of R, i.e. R.T @ R\n    return problem\n\ndef get_cofi_options_least_squares():\n    options = cofi.InversionOptions()\n    options.set_tool(\"scipy.sparse.linalg\")\n    options.set_params(algorithm=\"minres\")\n    return options\n\ndef least_squares_solution(mu, verbose=True):\n    problem = get_cofi_problem_least_squares(mu)\n    options = get_cofi_options_least_squares()\n    inv = cofi.Inversion(problem, options)\n    inv_results = inv.run()\n    if verbose:\n        inv.summary()\n    return 1 / ( inv_results.model + x0 ) # Phase velocity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tentative least-squares solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c_tentative = least_squares_solution(0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_map(phase_velocity):\n    global map_boundaries, transform\n    \"\"\"Plot a phase-velocity map on an equal-area grid\"\"\"\n    proj = ccrs.LambertConformal(central_longitude=135,\n                                 central_latitude=-27,\n                                 cutoff=80,\n                                 standard_parallels=(-18, -36)\n                                  )\n    fig = plt.figure(figsize=(5, 6.5))\n    ax = plt.subplot(111, projection=proj)\n    ax.coastlines()\n    img, cb = _plot_map(grid.mesh, phase_velocity, ax=ax, cmap=scm.roma, show=False)\n    cb.set_label('Phase velocity [km/s]')\n    ax.set_extent(map_boundaries, crs=transform)\n    plt.tight_layout()\n    plt.show()\n\n# Variables for plotting across the notebook\nproj = ccrs.LambertConformal(central_longitude=135,\n                             central_latitude=-27,\n                             cutoff=80,\n                             standard_parallels=(-18, -36)\n                              )\ntransform = ccrs.PlateCarree()\nmap_boundaries = [113, 153, -45, -8]\n\nplot_map(c_tentative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# L-curve analysis\n\nDue to a roughness-damping coeffient larger than ideal, the\nphase-velocity map shown above appears too smooth. In this section, we\nwill carry out an L-curve analysis to select a more meaningful\ncoefficient $\\mu$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def callback_func(inv_result, i):\n    global A, x0, regularization, d_obs, damping_coeffs\n    x = inv_result.model\n    d_pred = A @ (x + x0)\n    residual_norm = np.linalg.norm(d_obs - d_pred)\n    reg_norm = np.sqrt(regularization(x))\n    print(f\"Finished inversion with mu={damping_coeffs[i]}\")\n    print(f\"\\tRes. Norm: {round(residual_norm, 5)}, Reg. Norm {round(reg_norm, 5)}\")\n    return residual_norm, reg_norm\n    \n\ndamping_coeffs = np.logspace(-3, 2, 15)\nlcurve_problems = []\nfor mu in damping_coeffs:\n    problem = get_cofi_problem_least_squares(mu)\n    lcurve_problems.append(problem)\n\ninversion_pool = cofi.utils.InversionPool(\n    list_of_inv_problems=lcurve_problems,\n    list_of_inv_options=get_cofi_options_least_squares(),\n    callback=callback_func,\n    parallel=False\n)\nall_res, all_cb_returns = inversion_pool.run()\n\nl_curve_points = list(zip(*all_cb_returns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "residual_norm, regularization_norm = np.array(l_curve_points)\nplt.plot(residual_norm, regularization_norm, 'k.-')\nplt.xlabel(r'Norm of residual $||g(m)-d||_2$')\nplt.ylabel(r'Norm of regularization term $||Rm||_2$')\nfor damping, res_norm, reg_norm in zip(damping_coeffs, \n                                       residual_norm, \n                                       regularization_norm):\n    plt.plot(res_norm, reg_norm, 'ro')\n    plt.text(res_norm - res_norm*2e-3, \n             reg_norm - reg_norm*2e-3, \n             s=r'$%s$'%scientific_label(damping, 1), \n             va='top', \n             ha='right', \n             fontsize=8,\n             color='r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Least-squares solution with selected damping coefficient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "c = least_squares_solution(1e-2)\nplot_map(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above phase-velocity map aligns with that in [Magrini et\nal.\u00a0(2023)](https://doi.org/10.1029/2023JB026688).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Approach II: Trans-dimensional Bayesian Inversion\n\nIn this section, we use CoFI to estimate lateral variations in phase\nvelocity across Australia via reversible-jump Markov chain Monte Carlo\n(RJ-MCMC) sampling ([Green\n1995](https://doi.org/10.1093/biomet/82.4.711)). RJ-MCMC is is a\ngeneralization of the Metropolis-Hastings algorithm allowing for\ntrans-dimensional parameterizations. The algorithm starts from an\ninitial model $\\mathbf{m}$ and proposes a new model $\\mathbf{m}'$ based\non a perturbative approach. The new model is then accepted (in which\ncase, $\\mathbf{m} \\gets \\mathbf{m'}$) with probability `\\begin{equation}\n\\tag{4}\n\\alpha(\\mathbf{m'} \\mid \\mathbf{m}) = \n    \\underbrace{\\frac{p(\\mathbf{d} \\mid \\mathbf{m'})}{p(\\mathbf{d} \\mid \\mathbf{m})}}_{\\text{Likelihood ratio}}\n    \\underbrace{\\frac{p(\\mathbf{m'})}{p(\\mathbf{m})}}_{\\text{Prior ratio}}\n    \\underbrace{\\frac{q(\\mathbf{m} \\mid \\mathbf{m'})}{q(\\mathbf{m'} \\mid \\mathbf{m})}}_{\\text{Proposal ratio}} \n    |\\mathbf{J}|,\n\\end{equation}`{.interpreted-text role=\"raw-latex\"} where $p(a \\mid b)$\ndenotes the conditional probability of $a$ given $b$ and it is\nunderstood that $\\alpha = \\min(1, \\alpha)$. In the above expression, the\nJacobian $\\mathbf{J}$ of the transformation from $\\mathbf{m}$ to\n$\\mathbf{m}'$ accounts for the volume change in the parameter space\nunder the proposed transformation. Through the forward operator\n$\\mathbf{g}$, the likelihood expresses how well a model explains the\ndata, and reads `\\begin{equation}\n\\tag{5}\np(\\mathbf{d} | \\mathbf{m}) = \\frac{1}{\\sqrt{(2\\pi)^n |\\mathbf{C}_d|}} \\ \\exp \\left\\{\\frac{-\\Phi(\\mathbf{m})}{2} \\right\\},\n\\end{equation}`{.interpreted-text role=\"raw-latex\"} where $n$ denotes\nthe size of the data vector, $\\mathbf{C}_d$ the data covariance matrix,\nand `\\begin{equation}\n\\tag{6}\n\\Phi(\\mathbf{m}) = \\left[ \\mathbf{g}(\\mathbf{m}) - \\mathbf{d} \\right]^T \\mathbf{C}_d^{-1} \\left[ \\mathbf{g}(\\mathbf{m}) - \\mathbf{d} \\right]\n\\end{equation}`{.interpreted-text role=\"raw-latex\"} is the Mahalanobis\ndistance between observations and model predictions.\n\nIn MCMC methods, the process of proposing a new model and deciding\nwhether to accept it is repeated many times to build a sequence of\nmodels $\\mathcal{M} = \\{\\mathbf{m}_t\\}$, where $t$ denotes the Markov\nchain iteration. In practice, a\n`\\textit{burn-in period}`{.interpreted-text role=\"raw-latex\"} typically\nprecedes the generation of $\\mathcal{M}$ to allow convergence of the\nMarkov chain to a stationary distribution. Once the burn-in period is\ncompleted, the subsequent iterations are used to populate $\\mathcal{M}$,\nproviding an approximation to the posterior distribution\n`\\begin{equation}\n\\tag{7}\np(\\mathbf{m} \\mid \\mathbf{d}) \\propto p(\\mathbf{d} \\mid \\mathbf{m}) p(\\mathbf{m}).\n\\end{equation}`{.interpreted-text role=\"raw-latex\"}\n\nIn the following, we will sample the posterior using the\n[BayesBay](https://bayes-bay.readthedocs.io/en/latest/) library, which\nwe will select through the cofi.InversionOptions class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameterization\n\nWe discretize the Earth's surface using a trans-dimensional Voronoi\ntessellation, with each Voronoi cell corresponding to a phase-velocity\nvalue defined by a uniform prior between 2 and 4 km/s.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vel = bb.prior.UniformPrior('vel', vmin=2, vmax=4, perturb_std=0.1)\nvoronoi = bb.discretization.Voronoi2D(\n    name='voronoi', \n    polygon=polygon, \n    perturb_std=1, \n    n_dimensions_min=100, # Minimum number of Voronoi cells\n    n_dimensions_max=1500, # Maximum number of Voronoi cells\n    parameters=[vel], # Each cell has a value of phase velocity\n    compute_kdtree=True) # This stores a kd-tree for interpolating the Voronoi tessellation onto the equal-area grid we used earlier\nparameterization = bb.parameterization.Parameterization(voronoi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data and Likelihood\n\nWe treat the data noise as unknown by parameterizing the data covariance\nmatrix $\\mathbf{C}_d = \\sigma^2 \\mathbf{I}$ through the noise standard\ndeviation $\\sigma$, which is assigned a uniform prior distribution\nwithin the range 0--0.01 s/km.\n\nNote that, different from the previous section, obtaining forward\npredictions $\\mathbf{d}_{\\mathrm{pred}}$ presents two main challenges\nwhen using a trans-dimensional Voronoi tessellation (e.g., [Sambridge &\nGu\u0111mundsson 1998](https://doi.org/10.1029/97JB02602)). First, there are\nno analytical expressions for the intersections of a great-circle path\nwith Voronoi cell boundaries, complicating the calculation of $l_j$ in\neq. (1). Second, such intersections must be recomputed whenever the\ndiscretization is perturbed, which becomes increasingly expensive as the\nnumber of station pairs increases.\n\nTo address these issues, we will interpolate the phase velocity in each\nVoronoi cell onto the equal-area grid used in the previous section,\nthereby enabling the use of the matrix $\\mathbf{A}$ to obtain forward\npredictions. This behaviour is programmed in the function `_forward`, as\ndefined below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _forward(kdtree, vel):\n    global A, grid_points\n    nearest_neighbors = kdtree.query(grid_points)[1]\n    interp_vel = vel[nearest_neighbors]\n    return interp_vel, A @ (1 / interp_vel)\n\n\ndef forward(state):\n    voronoi = state[\"voronoi\"] # Voronoi nuclei\n    kdtree = voronoi.load_from_cache('kdtree') # Load the kd-tree for interpolation\n    interp_vel, d_pred = _forward(kdtree, voronoi.get_param_values('vel')) # Velocity model and dpred\n    state.save_to_extra_storage('interp_vel', interp_vel) # Save velocity model for plotting later\n    return d_pred\n\n\ntarget = bb.Target('d_obs', \n                   d_obs, \n                   std_min=0, # Minimum noise standard deviation\n                   std_max=0.01, # Maximum noise standard deviation\n                   std_perturb_std=0.001, # Standard deviation of the Gaussian used to perturb sigma\n                   noise_is_correlated=False)\nlog_likelihood = bb.LogLikelihood(targets=target, fwd_functions=forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CoFI Options and Bayesian Sampling\n\nWe sample the posterior via 12 Markov chains. We run each chain for\n350,000 iterations, and save one model every 100 starting from the\n150,000th iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_cofi_options_bayesian(n_chains, n_iterations, burnin_iterations, save_every):\n    starting_states = []\n    for _ in range(n_chains):\n        starting_states.append(parameterization.initialize()) # Randomly initialize Voronoi cells\n        log_likelihood.initialize(starting_states[-1]) # Evaluate the likelihood associated with the initial state\n\n    # Get the perturbation functions: Perturbation of phase velocity/Voronoi nuclei/noise and birth/death\n    perturbation_funcs = parameterization.perturbation_functions \n    \n    inv_options = cofi.InversionOptions()\n    inv_options.set_tool(\"bayesbay\")\n    inv_options.set_params(\n        walkers_starting_states=starting_states,\n        perturbation_funcs=perturbation_funcs,\n        log_like_ratio_func=log_likelihood,\n        n_chains=n_chains, \n        n_iterations=n_iterations, \n        burnin_iterations=burnin_iterations,\n        verbose=False, \n        save_every=save_every, \n    )\n    return inv_options\n\ninv = cofi.Inversion(cofi.BaseProblem(), \n                     get_cofi_options_bayesian(n_chains=12,\n                                               n_iterations=350_000,\n                                               burnin_iterations=150_000,\n                                               save_every=100))\ninv_results = inv.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the results\nsaved_states = inv_results.models\nstatistics = {\"mean\": np.mean(saved_states['interp_vel'], axis=0),\n              \"std\": np.std(saved_states['interp_vel'], axis=0),\n              \"std_noise\": saved_states['d_obs.std']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting a Voronoi tessellation in geographic coordinates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_tessellation_geographic(voronoi_sites, \n                                 param_values=None, \n                                 clip_polygon=None, \n                                 ax=None, \n                                 colorbar=True, \n                                 vmin=None, \n                                 vmax=None, \n                                 norm=None, \n                                 cmap='viridis'):\n    \"\"\"\n    Plots a Voronoi tessellation within a specified geographic polygon.\n    \n    :param voronoi_sites: Coordinates of the Voronoi sites.\n    :param param_values: Parameter values for coloring the Voronoi cells.\n    :param clip_polygon: The geographic boundary to clip the Voronoi tessellation.\n    :param ax: The matplotlib axis to plot on. Creates a new axis if None.\n    :param colorbar: Flag to indicate if a colorbar should be plotted.\n    :param vmin: The minimum value for the colormap normalization.\n    :param vmax: The maximum value for the colormap normalization.\n    :param norm: A matplotlib.colors.Normalize instance for normalizing the color mapping.\n    :param cmap: The colormap for the Voronoi cells.\n    :return: The matplotlib axis and colorbar (if created).\n    \"\"\"\n    # Extend the Voronoi sites with boundary points to enclose the tessellation.\n    boundary_points = np.array([[180, 90], [-180, 90], [180, -90], [-180, -90]])\n    sites = np.append(voronoi_sites, boundary_points, axis=0)\n    vor = scipy.spatial.Voronoi(sites)\n\n    # Sort and map the parameter values to the original Voronoi sites.\n    if param_values is not None:\n        isort = [np.flatnonzero(np.all(p == vor.points, axis=1)).item() for p in voronoi_sites]\n        param_values = param_values[isort]\n        vmin = vmin or min(param_values)\n        vmax = vmax or max(param_values)\n        norm = norm or mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n        cmap = mpl.cm.get_cmap(cmap) if isinstance(cmap, str) else cmap\n        colors = cmap(norm(param_values))\n    else:\n        colors = None\n\n    # Configure the map projection and axis.\n    proj = ccrs.LambertConformal(central_longitude=135, \n                                 central_latitude=-27, \n                                 cutoff=30, \n                                 standard_parallels=(-18, -36))\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': proj})\n\n    # Plot the Voronoi cells, clipped by the specified polygon.\n    for ipoint, iregion in enumerate(vor.point_region):\n        region = vor.regions[iregion]\n        if -1 not in region and region:\n            polygon = Polygon([vor.vertices[i] for i in region])\n            color = colors[ipoint] if colors is not None else 'none'\n            plot_polygon(ax, polygon, clip_polygon, color)\n\n    # Add a colorbar if requested.\n    cbar = plot_colorbar(ax, cmap, norm) if colorbar and param_values is not None else None\n\n    return ax, cbar\n\ndef plot_polygon(ax, polygon, clip_polygon, color):\n    \"\"\"\n    Clips a Voronoi polygon to the specified geographic boundary and plots it.\n    \"\"\"\n    if clip_polygon is not None:\n        polygon = polygon.intersection(clip_polygon)\n        if polygon.is_empty:\n            return\n        polygons = [polygon] if isinstance(polygon, Polygon) else polygon.geoms\n    else:\n        polygons = [polygon]\n\n    for geom in polygons:\n        ax.add_geometries([geom], crs=ccrs.PlateCarree(), facecolor=color, edgecolor='black', lw=0.5)\n\ndef plot_colorbar(ax, cmap, norm):\n    \"\"\"\n    Adds a colorbar to the plot.\n    \"\"\"\n    sm = ScalarMappable(cmap=cmap, norm=norm)\n    sm.set_array([])  # Dummy array for scalar mappable\n    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n    return cbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid_coarse = EqualAreaGrid(cell_size=0.35,\n                            lonmin=110,\n                            lonmax=157,\n                            latmin=-48,\n                            latmax=-4,\n                            verbose=False)\nidx_in_polygon = grid_coarse.indexes_in_polygon(polygon)\ngrid_coarse.select_cells(idx_in_polygon, inplace=True)\ngrid_points_coarse = np.column_stack(grid_coarse.midpoints_lon_lat())\n\n\ninferred_vel = scatter_to_mesh(grid_points[:, 1], \n                               grid_points[:, 0], \n                               statistics['mean'], \n                               grid_coarse.mesh)\nnotnan = np.flatnonzero(~np.isnan(inferred_vel))\ngrid_points_coarse = grid_points_coarse[notnan]\ninferred_vel = inferred_vel[notnan]\ninferred_std = scatter_to_mesh(grid_points[:, 1], \n                               grid_points[:, 0], \n                               statistics['std'], \n                               grid_coarse.mesh)[notnan]\n\ntriang = tri.Triangulation(*grid_points_coarse.T)\nlons_triang = grid_points_coarse[:,0][triang.triangles].mean(axis=1) \nlats_triang = grid_points_coarse[:,1][triang.triangles].mean(axis=1) \nmask = np.array([not polygon.contains(Point(lon, lat)) \\\n                 for lon, lat in zip(lons_triang, lats_triang)])\ntriang.set_mask(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverse_mask = box(-180, -90, 180, 90).difference(polygon)\npath = geos_to_path(inverse_mask)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting RJ-MCMC samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n\nfor i in range(1, 7):\n    ax = fig.add_subplot(2, 3, i, projection=proj)\n    random_index = np.random.choice(range(len(saved_states['voronoi.vel'])), \n                                    replace=False)\n    voronoi_sites = saved_states['voronoi.discretization'][random_index] \n    velocity = saved_states['voronoi.vel'][random_index] \n    ax, cbar = plot_tessellation_geographic(voronoi_sites, \n                                            velocity, \n                                            ax=ax, \n                                            cmap=scm.roma, \n                                            clip_polygon=polygon,\n                                            vmin=inferred_vel.min(),\n                                            vmax=inferred_vel.max(),\n                                            colorbar=False\n                                            )\n    ax.coastlines()\n    ax.add_patch(PathPatch(path, \n                           facecolor='white', \n                           edgecolor='none', \n                           transform=transform, \n                           zorder=2))\n    ax.set_extent(map_boundaries, crs=transform)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting average phase velocity and standard deviation maps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6.5))\nax1 = fig.add_subplot(1, 2, 1, projection=proj)\nimg = ax1.tricontourf(triang, \n                      inferred_vel, \n                      levels=75, \n                      cmap=scm.roma, \n                      transform=transform)\ncbar = make_colorbar(ax1, img, orientation='horizontal', size='3%', pad='2%')\ncbar.set_label('Phase velocity [km/s]')\n\nax2 = fig.add_subplot(1, 2, 2, projection=proj)\nimg = ax2.tricontourf(triang, \n                      inferred_std, \n                      levels=75, \n                      cmap=scm.imola, \n                      transform=transform)\ncbar = make_colorbar(ax2, img, orientation='horizontal', size='3%', pad='2%')\ncbar.set_label('Standard deviation [km/s]')\n\n\nfor ax in [ax1, ax2]:\n    ax.coastlines()\n    ax.set_extent(map_boundaries, crs=transform)\n    ax.add_patch(PathPatch(path, \n                           facecolor='white', \n                           edgecolor='none', \n                           transform=transform, \n                           zorder=2))\nplt.tight_layout()   \nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# Watermark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "watermark_list = [\"cofi\", \"espresso\", \"numpy\", \"matplotlib\", \"scipy\", \"seislib\"]\nfor pkg in watermark_list:\n    pkg_var = __import__(pkg)\n    print(pkg, getattr(pkg_var, \"__version__\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = -1\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}